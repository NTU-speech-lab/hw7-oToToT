{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_IPYTHON = True\n",
    "try:\n",
    "    __IPYTHON__\n",
    "except NameError:\n",
    "    IN_IPYTHON = False\n",
    "\n",
    "if IN_IPYTHON:\n",
    "    workspace_dir, output_fpath = 'food-11', 'predict.csv'\n",
    "else:\n",
    "    try:\n",
    "        workspace_dir = sys.argv[1]\n",
    "    except:\n",
    "        workspace_dir = 'food-11'\n",
    "\n",
    "    try:\n",
    "        output_fpath = sys.argv[2]\n",
    "    except:\n",
    "        output_fpath = \"predict.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "IMAGE_SIZE = 192\n",
    "def readfile(path, label):\n",
    "    # label 是一個 boolean variable，代表需不需要回傳 y 值\n",
    "    image_dir = sorted(os.listdir(path))\n",
    "    x = np.zeros((len(image_dir), IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.uint8)\n",
    "    y = np.zeros((len(image_dir)), dtype=np.uint8)\n",
    "    for i, file in enumerate(image_dir):\n",
    "        img = cv2.imread(os.path.join(path, file))\n",
    "        # resize to IMAGE_SIZE x ? or ? x IMAGE_SIZE\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        rate = IMAGE_SIZE / max(height, width)\n",
    "        height = int(height * rate)\n",
    "        width = int(width * rate)\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        # pad black\n",
    "        # from https://blog.csdn.net/qq_20622615/article/details/80929746\n",
    "        W, H = IMAGE_SIZE, IMAGE_SIZE\n",
    "        top = (H - height) // 2\n",
    "        bottom = (H - height) // 2\n",
    "        if top + bottom + height < H:\n",
    "            bottom += 1\n",
    "        left = (W - width) // 2\n",
    "        right = (W - width) // 2\n",
    "        if left + right + width < W:\n",
    "            right += 1\n",
    "        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        # to np array\n",
    "        x[i, :, :] = img\n",
    "        if label:\n",
    "            y[i] = int(file.split(\"_\")[0])\n",
    "    if label:\n",
    "      return x, y\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_mean = np.array([ 69.58238342,  92.66689336, 115.24940137]) / 255\n",
    "transform_std = np.array([71.8342021 , 76.83536755, 83.40123168]) / 255\n",
    "\n",
    "train_transform1 = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomChoice([\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomPerspective()\n",
    "    ]),\n",
    "    transforms.RandomChoice([\n",
    "        transforms.RandomAffine(10), # 隨機線性轉換\n",
    "        transforms.RandomRotation(40)\n",
    "    ]),\n",
    "    transforms.ColorJitter(), # 隨機色溫等\n",
    "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization)\n",
    "    transforms.Normalize(\n",
    "        transform_mean,\n",
    "        transform_std\n",
    "    )\n",
    "])\n",
    "train_transform2 = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomOrder([\n",
    "        transforms.RandomChoice([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomPerspective()\n",
    "        ]),\n",
    "        transforms.RandomAffine(30), # 隨機線性轉換\n",
    "        transforms.RandomResizedCrop((IMAGE_SIZE, IMAGE_SIZE), scale=(0.5, 1.0)), # 隨機子圖\n",
    "    ]),\n",
    "    transforms.RandomChoice([\n",
    "        transforms.ColorJitter(), # 隨機色溫等\n",
    "        transforms.RandomGrayscale(),\n",
    "    ]),\n",
    "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization)\n",
    "    transforms.RandomErasing(0.2),\n",
    "    transforms.Normalize(\n",
    "        transform_mean,\n",
    "        transform_std\n",
    "    )\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                                    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        transform_mean,\n",
    "        transform_std\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        # label is required to be a LongTensor\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "Size of training data = 9866\n",
      "Size of validation data = 3430\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading data\")\n",
    "train_x, train_y = readfile(os.path.join(workspace_dir, \"training\"), True)\n",
    "print(\"Size of training data = {}\".format(len(train_x)))\n",
    "val_x, val_y = readfile(os.path.join(workspace_dir, \"validation\"), True)\n",
    "print(\"Size of validation data = {}\".format(len(val_x)))\n",
    "\n",
    "batch_size = 128\n",
    "train_set = ConcatDataset([\n",
    "    ImgDataset(train_x, train_y, train_transform2),\n",
    "    ImgDataset(train_x, train_y, test_transform),\n",
    "#     ImgDataset(train_x, train_y, train_transform1),\n",
    "])\n",
    "val_set = ImgDataset(val_x, val_y, test_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=(16 if os.name=='posix' else 0))\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=(16 if os.name=='posix' else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALCULATE_STD_MEAN = False\n",
    "if CALCULATE_STD_MEAN:\n",
    "    tmp = ConcatDataset([train_set, val_set])\n",
    "    tot, tot2 = np.zeros(3), np.zeros(3)\n",
    "    tot_n = len(tmp) * IMAGE_SIZE ** 2\n",
    "    for x, y in tmp:\n",
    "        x = np.array(x, dtype=np.float64)\n",
    "        tot += x.sum(axis=(0,1))\n",
    "        tot2 += (x*x).sum(axis=(0,1))\n",
    "    tot /= tot_n\n",
    "    tot2 /= tot_n\n",
    "    tot, np.sqrt(tot2 - tot*tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TeacherNet_oToToT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TeacherNet_oToToT, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # input 維度 [3, IMAGE_SIZE, IMAGE_SIZE]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "            \n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "            \n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "            \n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(12*12*512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "                        \n",
    "            nn.Linear(1024, 11)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_net = TeacherNet_oToToT().cuda()\n",
    "# teacher_net.load_state_dict(torch.load('teacher_model.bin'))\n",
    "loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
    "optimizers = [\n",
    "    (torch.optim.Adam, 0.002),\n",
    "    (torch.optim.SGD, 0.001)\n",
    "]\n",
    "num_epochs = [\n",
    "    80,\n",
    "    250\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "TRAIN_TEACHER_NET = False\n",
    "\n",
    "if TRAIN_TEACHER_NET:\n",
    "    best_acc = 0\n",
    "\n",
    "    for (optimizer, lr), num_epoch in zip(optimizers, num_epochs):\n",
    "        optimizer = optimizer(teacher_net.parameters(), lr)\n",
    "        for epoch in range(num_epoch):\n",
    "            epoch_start_time = time.time()\n",
    "            train_acc = 0.0\n",
    "            train_loss = 0.0\n",
    "            val_acc = 0.0\n",
    "            val_loss = 0.0\n",
    "\n",
    "            teacher_net.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
    "            for i, data in enumerate(train_loader):\n",
    "                optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
    "                train_pred = teacher_net(data[0].cuda()) # 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
    "                batch_loss = loss(train_pred, data[1].cuda()) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
    "                batch_loss.backward() \n",
    "                optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
    "\n",
    "                train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "                train_loss += batch_loss.item()\n",
    "\n",
    "#             print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f' % \n",
    "#                 (epoch + 1, num_epoch, time.time()-epoch_start_time, train_acc/len(train_set), train_loss/len(train_set)))\n",
    "                \n",
    "            teacher_net.eval()\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(val_loader):\n",
    "                    val_pred = teacher_net(data[0].cuda())\n",
    "                    batch_loss = loss(val_pred, data[1].cuda())\n",
    "                    val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "                    val_loss += batch_loss.item()\n",
    "\n",
    "                if val_acc > best_acc:\n",
    "                    torch.save(teacher_net.state_dict(), 'teacher_model.bin')\n",
    "\n",
    "                #將結果 print 出來\n",
    "                print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \n",
    "                      (epoch + 1, num_epoch, time.time()-epoch_start_time, train_acc/len(train_set),\n",
    "                       train_loss/len(train_set), val_acc/len(val_set), val_loss/len(val_set)))\n",
    "#     torch.save(teacher_net.state_dict(), 'teacher_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_net = TeacherNet_oToToT().cuda()\n",
    "teacher_net.load_state_dict(torch.load('teacher_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_TEACHER_NET = False\n",
    "if CHECK_TEACHER_NET:\n",
    "    test_x = readfile(os.path.join(workspace_dir, \"testing\"), False)\n",
    "    print(\"Size of Testing data = {}\".format(len(test_x)))\n",
    "    test_set = ImgDataset(test_x, transform=test_transform)\n",
    "    test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=(16 if os.name=='posix' else 0))\n",
    "\n",
    "    teacher_net.eval()\n",
    "\n",
    "    prediction = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            test_pred = teacher_net(data.cuda())\n",
    "            test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "            for y in test_label:\n",
    "                prediction.append(y)\n",
    "\n",
    "    with open(output_fpath, 'w') as f:\n",
    "        f.write('Id,Category\\n')\n",
    "        for i, y in enumerate(prediction):\n",
    "            f.write('{},{}\\n'.format(i, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class swish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(swish, self).__init__()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = x * F.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    '''\n",
    "      在這個Net裡面，我們會使用Depthwise & Pointwise Convolution Layer來疊model。\n",
    "      你會發現，將原本的Convolution Layer換成Dw & Pw後，Accuracy通常不會降很多。\n",
    "\n",
    "      另外，取名為StudentNet是因為這個Model等會要做Knowledge Distillation。\n",
    "    '''\n",
    "\n",
    "    def __init__(self, base=16, width_mult=1):\n",
    "        '''\n",
    "          Args:\n",
    "            base: 這個model一開始的ch數量，每過一層都會*2，直到base*16為止。\n",
    "            width_mult: 為了之後的Network Pruning使用，在base*8 chs的Layer上會 * width_mult代表剪枝後的ch數量。        \n",
    "        '''\n",
    "        super(StudentNet, self).__init__()\n",
    "        multiplier = [2, 4, 4, 8, 8, 8, 8, 16, 16, 16, 16, 16, 16, 16]\n",
    "\n",
    "        # bandwidth: 每一層Layer所使用的ch數量\n",
    "        bandwidth = [int(base * m) for m in multiplier]\n",
    "\n",
    "        # 我們只Pruning第三層以後的Layer\n",
    "        for i in range(5, 13):\n",
    "            bandwidth[i] = int(bandwidth[i] * width_mult)\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            # 第一層我們通常不會拆解Convolution Layer。\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(3, bandwidth[0], 3, 1, 1),\n",
    "                nn.BatchNorm2d(bandwidth[0]),\n",
    "                nn.ReLU6(),\n",
    "                nn.MaxPool2d(2, 2, 0),\n",
    "            ),\n",
    "            # 接下來每一個Sequential Block都一樣，所以我們只講一個Block\n",
    "            nn.Sequential(\n",
    "                # Depthwise Convolution\n",
    "                nn.Conv2d(bandwidth[0], bandwidth[0], 3, 1, 1, groups=bandwidth[0]),\n",
    "                # Batch Normalization\n",
    "                nn.BatchNorm2d(bandwidth[0]),\n",
    "                # ReLU6 是限制Neuron最小只會到0，最大只會到6。 MobileNet系列都是使用ReLU6。\n",
    "                # 使用ReLU6的原因是因為如果數字太大，會不好壓到float16 / or further qunatization，因此才給個限制。\n",
    "                nn.ReLU6(),\n",
    "                # Pointwise Convolution\n",
    "                nn.Conv2d(bandwidth[0], bandwidth[1], 1),\n",
    "                # 過完Pointwise Convolution不需要再做ReLU，經驗上Pointwise + ReLU效果都會變差。\n",
    "                nn.MaxPool2d(2, 2, 0),\n",
    "                # 每過完一個Block就Down Sampling\n",
    "            ),\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[1], bandwidth[1], 3, 1, 1, groups=bandwidth[1]),\n",
    "                nn.BatchNorm2d(bandwidth[1]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[1], bandwidth[2], 1),\n",
    "                nn.MaxPool2d(2, 2, 0),\n",
    "            ),\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[2], bandwidth[2], 3, 1, 1, groups=bandwidth[2]),\n",
    "                nn.BatchNorm2d(bandwidth[2]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[2], bandwidth[3], 1),\n",
    "                nn.MaxPool2d(2, 2, 0),\n",
    "            ),\n",
    "            \n",
    "            # 到這邊為止因為圖片已經被Down Sample很多次了，所以就不做MaxPool\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[3], bandwidth[3], 3, 1, 1, groups=bandwidth[3]),\n",
    "                nn.BatchNorm2d(bandwidth[3]),\n",
    "                nn.ReLU6(),\n",
    "                nn.Conv2d(bandwidth[3], bandwidth[4], 1),\n",
    "            ),\n",
    "            \n",
    "            *[\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(bandwidth[_], bandwidth[_], 3, 1, 1, groups=bandwidth[_]),\n",
    "                    nn.BatchNorm2d(bandwidth[_]),\n",
    "                    swish(),\n",
    "                    nn.Conv2d(bandwidth[_], bandwidth[_ + 1], 1),\n",
    "                ) for _ in range(4, 13)\n",
    "            ],\n",
    "\n",
    "            # 這邊我們採用Global Average Pooling。\n",
    "            # 如果輸入圖片大小不一樣的話，就會因為Global Average Pooling壓成一樣的形狀，這樣子接下來做FC就不會對不起來。\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            # 這邊我們直接Project到11維輸出答案。\n",
    "            nn.Linear(bandwidth[13], 160),\n",
    "            nn.BatchNorm1d(160),\n",
    "            nn.ReLU6(),\n",
    "            \n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(160, 160),\n",
    "            nn.BatchNorm1d(160),\n",
    "            swish(),\n",
    "                        \n",
    "            nn.Linear(160, 11)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_kd(outputs, labels, teacher_outputs, T=20, alpha=0.5):\n",
    "    # 一般的Cross Entropy\n",
    "    hard_loss = F.cross_entropy(outputs, labels) * (1. - alpha)\n",
    "    # 讓logits的log_softmax對目標機率(teacher的logits/T後softmax)做KL Divergence。\n",
    "    soft_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs/T, dim=1),\n",
    "                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T)\n",
    "    return hard_loss + soft_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 192, 192]             448\n",
      "       BatchNorm2d-2         [-1, 16, 192, 192]              32\n",
      "             ReLU6-3         [-1, 16, 192, 192]               0\n",
      "         MaxPool2d-4           [-1, 16, 96, 96]               0\n",
      "            Conv2d-5           [-1, 16, 96, 96]             160\n",
      "       BatchNorm2d-6           [-1, 16, 96, 96]              32\n",
      "             ReLU6-7           [-1, 16, 96, 96]               0\n",
      "            Conv2d-8           [-1, 32, 96, 96]             544\n",
      "         MaxPool2d-9           [-1, 32, 48, 48]               0\n",
      "           Conv2d-10           [-1, 32, 48, 48]             320\n",
      "      BatchNorm2d-11           [-1, 32, 48, 48]              64\n",
      "            ReLU6-12           [-1, 32, 48, 48]               0\n",
      "           Conv2d-13           [-1, 32, 48, 48]           1,056\n",
      "        MaxPool2d-14           [-1, 32, 24, 24]               0\n",
      "           Conv2d-15           [-1, 32, 24, 24]             320\n",
      "      BatchNorm2d-16           [-1, 32, 24, 24]              64\n",
      "            ReLU6-17           [-1, 32, 24, 24]               0\n",
      "           Conv2d-18           [-1, 64, 24, 24]           2,112\n",
      "        MaxPool2d-19           [-1, 64, 12, 12]               0\n",
      "           Conv2d-20           [-1, 64, 12, 12]             640\n",
      "      BatchNorm2d-21           [-1, 64, 12, 12]             128\n",
      "            ReLU6-22           [-1, 64, 12, 12]               0\n",
      "           Conv2d-23           [-1, 64, 12, 12]           4,160\n",
      "           Conv2d-24           [-1, 64, 12, 12]             640\n",
      "      BatchNorm2d-25           [-1, 64, 12, 12]             128\n",
      "            swish-26           [-1, 64, 12, 12]               0\n",
      "           Conv2d-27           [-1, 64, 12, 12]           4,160\n",
      "           Conv2d-28           [-1, 64, 12, 12]             640\n",
      "      BatchNorm2d-29           [-1, 64, 12, 12]             128\n",
      "            swish-30           [-1, 64, 12, 12]               0\n",
      "           Conv2d-31           [-1, 64, 12, 12]           4,160\n",
      "           Conv2d-32           [-1, 64, 12, 12]             640\n",
      "      BatchNorm2d-33           [-1, 64, 12, 12]             128\n",
      "            swish-34           [-1, 64, 12, 12]               0\n",
      "           Conv2d-35          [-1, 128, 12, 12]           8,320\n",
      "           Conv2d-36          [-1, 128, 12, 12]           1,280\n",
      "      BatchNorm2d-37          [-1, 128, 12, 12]             256\n",
      "            swish-38          [-1, 128, 12, 12]               0\n",
      "           Conv2d-39          [-1, 128, 12, 12]          16,512\n",
      "           Conv2d-40          [-1, 128, 12, 12]           1,280\n",
      "      BatchNorm2d-41          [-1, 128, 12, 12]             256\n",
      "            swish-42          [-1, 128, 12, 12]               0\n",
      "           Conv2d-43          [-1, 128, 12, 12]          16,512\n",
      "           Conv2d-44          [-1, 128, 12, 12]           1,280\n",
      "      BatchNorm2d-45          [-1, 128, 12, 12]             256\n",
      "            swish-46          [-1, 128, 12, 12]               0\n",
      "           Conv2d-47          [-1, 128, 12, 12]          16,512\n",
      "           Conv2d-48          [-1, 128, 12, 12]           1,280\n",
      "      BatchNorm2d-49          [-1, 128, 12, 12]             256\n",
      "            swish-50          [-1, 128, 12, 12]               0\n",
      "           Conv2d-51          [-1, 128, 12, 12]          16,512\n",
      "           Conv2d-52          [-1, 128, 12, 12]           1,280\n",
      "      BatchNorm2d-53          [-1, 128, 12, 12]             256\n",
      "            swish-54          [-1, 128, 12, 12]               0\n",
      "           Conv2d-55          [-1, 128, 12, 12]          16,512\n",
      "           Conv2d-56          [-1, 128, 12, 12]           1,280\n",
      "      BatchNorm2d-57          [-1, 128, 12, 12]             256\n",
      "            swish-58          [-1, 128, 12, 12]               0\n",
      "           Conv2d-59          [-1, 128, 12, 12]          16,512\n",
      "AdaptiveAvgPool2d-60            [-1, 128, 1, 1]               0\n",
      "           Linear-61                  [-1, 160]          20,640\n",
      "      BatchNorm1d-62                  [-1, 160]             320\n",
      "            ReLU6-63                  [-1, 160]               0\n",
      "          Dropout-64                  [-1, 160]               0\n",
      "           Linear-65                  [-1, 160]          25,760\n",
      "      BatchNorm1d-66                  [-1, 160]             320\n",
      "            swish-67                  [-1, 160]               0\n",
      "           Linear-68                   [-1, 11]           1,771\n",
      "================================================================\n",
      "Total params: 186,123\n",
      "Trainable params: 186,123\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.42\n",
      "Forward/backward pass size (MB): 28.56\n",
      "Params size (MB): 0.71\n",
      "Estimated Total Size (MB): 29.69\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "student_net_base = 8\n",
    "student_net = StudentNet(student_net_base).cuda()\n",
    "\n",
    "summary(student_net, (3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "optimizer = torch.optim.Adam(student_net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(dataloader, update=True, alpha=0.5):\n",
    "    total_num, total_hit, total_loss = 0, 0, 0\n",
    "    for now_step, batch_data in enumerate(dataloader):\n",
    "        # 清空 optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # 處理 input\n",
    "        inputs, hard_labels = batch_data\n",
    "        inputs = inputs.cuda()\n",
    "        hard_labels = torch.LongTensor(hard_labels).cuda()\n",
    "        # 因為Teacher沒有要backprop，所以我們使用torch.no_grad\n",
    "        # 告訴torch不要暫存中間值(去做backprop)以浪費記憶體空間。\n",
    "        with torch.no_grad():\n",
    "            soft_labels = teacher_net(inputs)\n",
    "\n",
    "        if update:\n",
    "            logits = student_net(inputs)\n",
    "            # 使用我們之前所寫的融合soft label&hard label的loss。\n",
    "            # T=20是原始論文的參數設定。\n",
    "            loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "        else:\n",
    "            # 只是算validation acc的話，就開no_grad節省空間。\n",
    "            with torch.no_grad():\n",
    "                logits = student_net(inputs)\n",
    "                loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n",
    "            \n",
    "        total_hit += torch.sum(torch.argmax(logits, dim=1) == hard_labels).item()\n",
    "        total_num += len(inputs)\n",
    "\n",
    "        total_loss += loss.item() * len(inputs)\n",
    "    return total_loss / total_num, total_hit / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epoch = 0\n",
    "\n",
    "# TeacherNet永遠都是Eval mode.\n",
    "teacher_net.eval()\n",
    "now_best_acc = 0.84\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    student_net.train()\n",
    "    train_loss, train_acc = run_epoch(train_loader, update=True)\n",
    "    student_net.eval()\n",
    "    valid_loss, valid_acc = run_epoch(val_loader, update=False)\n",
    "\n",
    "    # 存下最好的model。\n",
    "    if valid_acc > now_best_acc:\n",
    "        now_best_acc = valid_acc\n",
    "        torch.save(student_net.state_dict(), 'student_model.bin')\n",
    "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \n",
    "            (epoch + 1, num_epoch, time.time()-epoch_start_time, train_acc,\n",
    "            train_loss, valid_acc, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/200] 39.56 sec(s) Train Acc: 0.217667 Loss: 2.203395 | Val Acc: 0.221866 loss: 2.138959\n",
      "[002/200] 40.02 sec(s) Train Acc: 0.235506 Loss: 2.145249 | Val Acc: 0.238776 loss: 2.118534\n",
      "[003/200] 40.31 sec(s) Train Acc: 0.222937 Loss: 2.168748 | Val Acc: 0.228571 loss: 2.135883\n",
      "[004/200] 40.80 sec(s) Train Acc: 0.226079 Loss: 2.166416 | Val Acc: 0.234402 loss: 2.124787\n",
      "[005/200] 41.30 sec(s) Train Acc: 0.217515 Loss: 2.195265 | Val Acc: 0.230321 loss: 2.160595\n",
      "[006/200] 41.79 sec(s) Train Acc: 0.227448 Loss: 2.172449 | Val Acc: 0.202041 loss: 2.200933\n",
      "[007/200] 41.93 sec(s) Train Acc: 0.213967 Loss: 2.209075 | Val Acc: 0.205831 loss: 2.233175\n",
      "[008/200] 41.45 sec(s) Train Acc: 0.200740 Loss: 2.219565 | Val Acc: 0.186297 loss: 2.239271\n",
      "[009/200] 41.53 sec(s) Train Acc: 0.195368 Loss: 2.234588 | Val Acc: 0.186006 loss: 2.218773\n",
      "[010/200] 41.45 sec(s) Train Acc: 0.193594 Loss: 2.224470 | Val Acc: 0.206997 loss: 2.206872\n",
      "[011/200] 41.43 sec(s) Train Acc: 0.204693 Loss: 2.200051 | Val Acc: 0.188921 loss: 2.209231\n",
      "[012/200] 41.60 sec(s) Train Acc: 0.193543 Loss: 2.223618 | Val Acc: 0.186880 loss: 2.219187\n",
      "[013/200] 41.54 sec(s) Train Acc: 0.191770 Loss: 2.229630 | Val Acc: 0.188047 loss: 2.214485\n",
      "[014/200] 42.10 sec(s) Train Acc: 0.190199 Loss: 2.226500 | Val Acc: 0.199125 loss: 2.221089\n",
      "[015/200] 41.55 sec(s) Train Acc: 0.202767 Loss: 2.214439 | Val Acc: 0.193878 loss: 2.208343\n",
      "[016/200] 41.65 sec(s) Train Acc: 0.187462 Loss: 2.241665 | Val Acc: 0.196501 loss: 2.201957\n",
      "[017/200] 41.23 sec(s) Train Acc: 0.191212 Loss: 2.228734 | Val Acc: 0.201749 loss: 2.195954\n",
      "[018/200] 41.36 sec(s) Train Acc: 0.198409 Loss: 2.225990 | Val Acc: 0.200000 loss: 2.212392\n",
      "[019/200] 41.05 sec(s) Train Acc: 0.197648 Loss: 2.223094 | Val Acc: 0.206997 loss: 2.200768\n",
      "[020/200] 41.41 sec(s) Train Acc: 0.198459 Loss: 2.210255 | Val Acc: 0.222449 loss: 2.155384\n",
      "[021/200] 41.74 sec(s) Train Acc: 0.215741 Loss: 2.173828 | Val Acc: 0.234111 loss: 2.135370\n",
      "[022/200] 41.72 sec(s) Train Acc: 0.221822 Loss: 2.165741 | Val Acc: 0.237026 loss: 2.134106\n",
      "[023/200] 41.58 sec(s) Train Acc: 0.220860 Loss: 2.164093 | Val Acc: 0.244606 loss: 2.123435\n",
      "[024/200] 41.46 sec(s) Train Acc: 0.222431 Loss: 2.154529 | Val Acc: 0.239067 loss: 2.129037\n",
      "[025/200] 41.62 sec(s) Train Acc: 0.227296 Loss: 2.147031 | Val Acc: 0.242566 loss: 2.108510\n",
      "[026/200] 41.47 sec(s) Train Acc: 0.225319 Loss: 2.149204 | Val Acc: 0.237901 loss: 2.122232\n",
      "[027/200] 41.86 sec(s) Train Acc: 0.227955 Loss: 2.146213 | Val Acc: 0.225364 loss: 2.142669\n",
      "[028/200] 41.96 sec(s) Train Acc: 0.226738 Loss: 2.146133 | Val Acc: 0.242274 loss: 2.125733\n",
      "[029/200] 42.09 sec(s) Train Acc: 0.230387 Loss: 2.144472 | Val Acc: 0.223324 loss: 2.151854\n",
      "[030/200] 41.30 sec(s) Train Acc: 0.228867 Loss: 2.144107 | Val Acc: 0.236443 loss: 2.126876\n",
      "[031/200] 41.67 sec(s) Train Acc: 0.231350 Loss: 2.136839 | Val Acc: 0.237609 loss: 2.121893\n",
      "[032/200] 41.37 sec(s) Train Acc: 0.225015 Loss: 2.150938 | Val Acc: 0.216035 loss: 2.149818\n",
      "[033/200] 41.55 sec(s) Train Acc: 0.224711 Loss: 2.149298 | Val Acc: 0.223032 loss: 2.149614\n",
      "[034/200] 42.08 sec(s) Train Acc: 0.227955 Loss: 2.149237 | Val Acc: 0.216910 loss: 2.153745\n",
      "[035/200] 41.58 sec(s) Train Acc: 0.225066 Loss: 2.146499 | Val Acc: 0.230612 loss: 2.125032\n",
      "[036/200] 41.73 sec(s) Train Acc: 0.227904 Loss: 2.146141 | Val Acc: 0.236735 loss: 2.130688\n",
      "[037/200] 41.59 sec(s) Train Acc: 0.222481 Loss: 2.145029 | Val Acc: 0.232362 loss: 2.133184\n",
      "[038/200] 41.82 sec(s) Train Acc: 0.225522 Loss: 2.147218 | Val Acc: 0.236443 loss: 2.128714\n",
      "[039/200] 41.88 sec(s) Train Acc: 0.228512 Loss: 2.149276 | Val Acc: 0.230904 loss: 2.134687\n",
      "[040/200] 41.75 sec(s) Train Acc: 0.228715 Loss: 2.148385 | Val Acc: 0.234402 loss: 2.129934\n",
      "[041/200] 41.88 sec(s) Train Acc: 0.208697 Loss: 2.204251 | Val Acc: 0.233528 loss: 2.160762\n",
      "[042/200] 41.62 sec(s) Train Acc: 0.212852 Loss: 2.195216 | Val Acc: 0.226239 loss: 2.174949\n",
      "[043/200] 42.12 sec(s) Train Acc: 0.214069 Loss: 2.189164 | Val Acc: 0.225948 loss: 2.167513\n",
      "[044/200] 41.54 sec(s) Train Acc: 0.220403 Loss: 2.179948 | Val Acc: 0.232070 loss: 2.153370\n",
      "[045/200] 41.73 sec(s) Train Acc: 0.213866 Loss: 2.183085 | Val Acc: 0.228863 loss: 2.171206\n",
      "[046/200] 41.50 sec(s) Train Acc: 0.215488 Loss: 2.182468 | Val Acc: 0.222741 loss: 2.173419\n",
      "[047/200] 41.62 sec(s) Train Acc: 0.213815 Loss: 2.184534 | Val Acc: 0.231778 loss: 2.159767\n",
      "[048/200] 41.73 sec(s) Train Acc: 0.214069 Loss: 2.183921 | Val Acc: 0.227988 loss: 2.155902\n",
      "[049/200] 41.46 sec(s) Train Acc: 0.216197 Loss: 2.182670 | Val Acc: 0.227697 loss: 2.163303\n",
      "[050/200] 42.05 sec(s) Train Acc: 0.218478 Loss: 2.179399 | Val Acc: 0.219242 loss: 2.168450\n",
      "[051/200] 41.91 sec(s) Train Acc: 0.218528 Loss: 2.177354 | Val Acc: 0.213411 loss: 2.178006\n",
      "[052/200] 41.74 sec(s) Train Acc: 0.215842 Loss: 2.178033 | Val Acc: 0.231778 loss: 2.183307\n",
      "[053/200] 41.60 sec(s) Train Acc: 0.220251 Loss: 2.177796 | Val Acc: 0.194169 loss: 2.228886\n",
      "[054/200] 42.01 sec(s) Train Acc: 0.216197 Loss: 2.177601 | Val Acc: 0.208163 loss: 2.169302\n",
      "[055/200] 41.79 sec(s) Train Acc: 0.219542 Loss: 2.177544 | Val Acc: 0.230904 loss: 2.166593\n",
      "[056/200] 41.47 sec(s) Train Acc: 0.218630 Loss: 2.183001 | Val Acc: 0.232070 loss: 2.169639\n",
      "[057/200] 42.58 sec(s) Train Acc: 0.222177 Loss: 2.176627 | Val Acc: 0.221866 loss: 2.172732\n",
      "[058/200] 41.91 sec(s) Train Acc: 0.217109 Loss: 2.181165 | Val Acc: 0.228280 loss: 2.167900\n",
      "[059/200] 41.59 sec(s) Train Acc: 0.218021 Loss: 2.186502 | Val Acc: 0.227697 loss: 2.185809\n",
      "[060/200] 41.76 sec(s) Train Acc: 0.212193 Loss: 2.192779 | Val Acc: 0.230612 loss: 2.155802\n",
      "[061/200] 41.48 sec(s) Train Acc: 0.210876 Loss: 2.196535 | Val Acc: 0.225073 loss: 2.175844\n",
      "[062/200] 42.53 sec(s) Train Acc: 0.213359 Loss: 2.190228 | Val Acc: 0.215743 loss: 2.186348\n",
      "[063/200] 42.53 sec(s) Train Acc: 0.214575 Loss: 2.190762 | Val Acc: 0.239359 loss: 2.178764\n",
      "[064/200] 41.93 sec(s) Train Acc: 0.212345 Loss: 2.192634 | Val Acc: 0.217784 loss: 2.176904\n",
      "[065/200] 42.01 sec(s) Train Acc: 0.209153 Loss: 2.195104 | Val Acc: 0.218659 loss: 2.176268\n",
      "[066/200] 42.00 sec(s) Train Acc: 0.215488 Loss: 2.188953 | Val Acc: 0.227114 loss: 2.171584\n",
      "[067/200] 41.87 sec(s) Train Acc: 0.214727 Loss: 2.193207 | Val Acc: 0.207289 loss: 2.190312\n",
      "[068/200] 41.80 sec(s) Train Acc: 0.214930 Loss: 2.192194 | Val Acc: 0.217493 loss: 2.188828\n",
      "[069/200] 41.83 sec(s) Train Acc: 0.208595 Loss: 2.205845 | Val Acc: 0.202915 loss: 2.242337\n",
      "[070/200] 41.87 sec(s) Train Acc: 0.207531 Loss: 2.206518 | Val Acc: 0.219242 loss: 2.201335\n",
      "[071/200] 42.09 sec(s) Train Acc: 0.204592 Loss: 2.213971 | Val Acc: 0.213703 loss: 2.240308\n",
      "[072/200] 42.20 sec(s) Train Acc: 0.198003 Loss: 2.220119 | Val Acc: 0.200292 loss: 2.253169\n",
      "[073/200] 41.92 sec(s) Train Acc: 0.200588 Loss: 2.217627 | Val Acc: 0.175510 loss: 2.269481\n",
      "[074/200] 41.68 sec(s) Train Acc: 0.198206 Loss: 2.215016 | Val Acc: 0.214286 loss: 2.201367\n",
      "[075/200] 41.88 sec(s) Train Acc: 0.196736 Loss: 2.223126 | Val Acc: 0.191254 loss: 2.249833\n",
      "[076/200] 41.85 sec(s) Train Acc: 0.201247 Loss: 2.215589 | Val Acc: 0.207289 loss: 2.223408\n",
      "[077/200] 41.68 sec(s) Train Acc: 0.202615 Loss: 2.214087 | Val Acc: 0.195044 loss: 2.221209\n",
      "[078/200] 41.84 sec(s) Train Acc: 0.190503 Loss: 2.231545 | Val Acc: 0.182216 loss: 2.254483\n",
      "[079/200] 41.89 sec(s) Train Acc: 0.186094 Loss: 2.238123 | Val Acc: 0.206706 loss: 2.217579\n",
      "[080/200] 41.71 sec(s) Train Acc: 0.192733 Loss: 2.240465 | Val Acc: 0.194752 loss: 2.247085\n",
      "[081/200] 41.56 sec(s) Train Acc: 0.193087 Loss: 2.236141 | Val Acc: 0.193003 loss: 2.245712\n",
      "[082/200] 41.57 sec(s) Train Acc: 0.181887 Loss: 2.254496 | Val Acc: 0.181050 loss: 2.240035\n",
      "[083/200] 41.67 sec(s) Train Acc: 0.179455 Loss: 2.247103 | Val Acc: 0.178426 loss: 2.249552\n",
      "[084/200] 41.82 sec(s) Train Acc: 0.187817 Loss: 2.244625 | Val Acc: 0.198251 loss: 2.228733\n",
      "[085/200] 41.82 sec(s) Train Acc: 0.185638 Loss: 2.246988 | Val Acc: 0.170262 loss: 2.272167\n",
      "[086/200] 42.19 sec(s) Train Acc: 0.195875 Loss: 2.245726 | Val Acc: 0.161224 loss: 2.321116\n",
      "[087/200] 41.88 sec(s) Train Acc: 0.192124 Loss: 2.245016 | Val Acc: 0.159475 loss: 2.307593\n",
      "[088/200] 41.59 sec(s) Train Acc: 0.195368 Loss: 2.240150 | Val Acc: 0.202041 loss: 2.233101\n",
      "[089/200] 41.51 sec(s) Train Acc: 0.201095 Loss: 2.226098 | Val Acc: 0.190087 loss: 2.244851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[090/200] 41.73 sec(s) Train Acc: 0.201145 Loss: 2.226241 | Val Acc: 0.183673 loss: 2.243764\n",
      "[091/200] 41.73 sec(s) Train Acc: 0.192631 Loss: 2.236214 | Val Acc: 0.165598 loss: 2.266110\n",
      "[092/200] 41.60 sec(s) Train Acc: 0.193341 Loss: 2.243590 | Val Acc: 0.159767 loss: 2.291364\n",
      "[093/200] 41.86 sec(s) Train Acc: 0.190959 Loss: 2.243233 | Val Acc: 0.166472 loss: 2.268293\n",
      "[094/200] 41.86 sec(s) Train Acc: 0.197142 Loss: 2.237805 | Val Acc: 0.184548 loss: 2.270989\n",
      "[095/200] 41.72 sec(s) Train Acc: 0.199169 Loss: 2.230646 | Val Acc: 0.162974 loss: 2.305685\n",
      "[096/200] 41.52 sec(s) Train Acc: 0.197648 Loss: 2.228375 | Val Acc: 0.167930 loss: 2.251294\n",
      "[097/200] 41.54 sec(s) Train Acc: 0.202159 Loss: 2.223994 | Val Acc: 0.148397 loss: 2.313702\n",
      "[098/200] 41.71 sec(s) Train Acc: 0.204642 Loss: 2.215136 | Val Acc: 0.177259 loss: 2.277352\n",
      "[099/200] 41.65 sec(s) Train Acc: 0.201855 Loss: 2.219134 | Val Acc: 0.175802 loss: 2.352398\n",
      "[100/200] 41.95 sec(s) Train Acc: 0.204135 Loss: 2.217177 | Val Acc: 0.149854 loss: 2.965484\n",
      "[101/200] 41.77 sec(s) Train Acc: 0.204693 Loss: 2.213362 | Val Acc: 0.152478 loss: 2.912448\n",
      "[102/200] 41.56 sec(s) Train Acc: 0.206517 Loss: 2.215457 | Val Acc: 0.192711 loss: 2.258894\n",
      "[103/200] 41.81 sec(s) Train Acc: 0.207734 Loss: 2.210246 | Val Acc: 0.163848 loss: 2.261533\n",
      "[104/200] 42.20 sec(s) Train Acc: 0.206416 Loss: 2.217796 | Val Acc: 0.179009 loss: 2.271328\n",
      "[105/200] 41.79 sec(s) Train Acc: 0.206973 Loss: 2.210850 | Val Acc: 0.167638 loss: 2.287836\n",
      "[106/200] 41.65 sec(s) Train Acc: 0.204794 Loss: 2.211165 | Val Acc: 0.176968 loss: 2.276057\n",
      "[107/200] 41.88 sec(s) Train Acc: 0.204693 Loss: 2.207620 | Val Acc: 0.184548 loss: 2.264893\n",
      "[108/200] 41.71 sec(s) Train Acc: 0.206467 Loss: 2.209624 | Val Acc: 0.162974 loss: 2.311091\n",
      "[109/200] 41.60 sec(s) Train Acc: 0.206821 Loss: 2.212333 | Val Acc: 0.151603 loss: 2.283255\n",
      "[110/200] 42.29 sec(s) Train Acc: 0.206669 Loss: 2.214485 | Val Acc: 0.138484 loss: 2.298481\n",
      "[111/200] 42.10 sec(s) Train Acc: 0.210876 Loss: 2.211147 | Val Acc: 0.161224 loss: 2.299201\n",
      "[112/200] 41.68 sec(s) Train Acc: 0.212852 Loss: 2.205005 | Val Acc: 0.161516 loss: 2.279318\n",
      "[113/200] 41.54 sec(s) Train Acc: 0.209964 Loss: 2.206219 | Val Acc: 0.189213 loss: 2.237969\n",
      "[114/200] 41.94 sec(s) Train Acc: 0.205757 Loss: 2.204728 | Val Acc: 0.173178 loss: 2.263797\n",
      "[115/200] 41.98 sec(s) Train Acc: 0.211737 Loss: 2.204784 | Val Acc: 0.160350 loss: 2.256407\n",
      "[116/200] 41.91 sec(s) Train Acc: 0.206872 Loss: 2.209529 | Val Acc: 0.197376 loss: 2.292110\n",
      "[117/200] 41.77 sec(s) Train Acc: 0.209659 Loss: 2.208609 | Val Acc: 0.193294 loss: 2.258364\n",
      "[118/200] 41.91 sec(s) Train Acc: 0.205352 Loss: 2.207463 | Val Acc: 0.165598 loss: 2.280077\n",
      "[119/200] 41.92 sec(s) Train Acc: 0.213156 Loss: 2.206256 | Val Acc: 0.189504 loss: 2.232848\n",
      "[120/200] 41.89 sec(s) Train Acc: 0.211585 Loss: 2.203432 | Val Acc: 0.199125 loss: 2.246940\n",
      "[121/200] 41.89 sec(s) Train Acc: 0.212751 Loss: 2.201239 | Val Acc: 0.206122 loss: 2.270592\n",
      "[122/200] 42.11 sec(s) Train Acc: 0.215488 Loss: 2.199939 | Val Acc: 0.197668 loss: 2.276402\n",
      "[123/200] 41.96 sec(s) Train Acc: 0.212244 Loss: 2.203794 | Val Acc: 0.187172 loss: 2.262716\n",
      "[124/200] 41.91 sec(s) Train Acc: 0.212954 Loss: 2.201669 | Val Acc: 0.194752 loss: 2.263873\n",
      "[125/200] 41.91 sec(s) Train Acc: 0.213663 Loss: 2.202783 | Val Acc: 0.176385 loss: 2.313266\n",
      "[126/200] 42.02 sec(s) Train Acc: 0.215842 Loss: 2.201240 | Val Acc: 0.188921 loss: 2.277068\n",
      "[127/200] 41.93 sec(s) Train Acc: 0.213106 Loss: 2.202306 | Val Acc: 0.201166 loss: 2.249055\n",
      "[128/200] 41.95 sec(s) Train Acc: 0.207024 Loss: 2.207355 | Val Acc: 0.125364 loss: 2.434730\n",
      "[129/200] 42.03 sec(s) Train Acc: 0.191618 Loss: 2.236696 | Val Acc: 0.172303 loss: 2.268380\n",
      "[130/200] 41.89 sec(s) Train Acc: 0.198105 Loss: 2.224427 | Val Acc: 0.179592 loss: 2.266901\n",
      "[131/200] 41.74 sec(s) Train Acc: 0.201399 Loss: 2.217601 | Val Acc: 0.171137 loss: 2.409225\n",
      "[132/200] 41.84 sec(s) Train Acc: 0.203933 Loss: 2.215657 | Val Acc: 0.177551 loss: 2.297201\n",
      "[133/200] 41.96 sec(s) Train Acc: 0.203426 Loss: 2.211460 | Val Acc: 0.196210 loss: 2.253215\n",
      "[134/200] 41.73 sec(s) Train Acc: 0.201500 Loss: 2.214722 | Val Acc: 0.186006 loss: 2.254668\n",
      "[135/200] 41.70 sec(s) Train Acc: 0.206264 Loss: 2.211044 | Val Acc: 0.164723 loss: 2.341750\n",
      "[136/200] 41.88 sec(s) Train Acc: 0.205605 Loss: 2.208333 | Val Acc: 0.182216 loss: 2.364807\n",
      "[137/200] 41.70 sec(s) Train Acc: 0.208595 Loss: 2.206434 | Val Acc: 0.176093 loss: 2.309455\n",
      "[138/200] 41.77 sec(s) Train Acc: 0.205859 Loss: 2.208542 | Val Acc: 0.178426 loss: 2.249174\n",
      "[139/200] 41.63 sec(s) Train Acc: 0.207480 Loss: 2.209667 | Val Acc: 0.200292 loss: 2.250342\n",
      "[140/200] 41.78 sec(s) Train Acc: 0.206365 Loss: 2.210100 | Val Acc: 0.168222 loss: 2.463812\n",
      "[141/200] 41.88 sec(s) Train Acc: 0.203679 Loss: 2.208462 | Val Acc: 0.164140 loss: 2.344050\n",
      "[142/200] 42.00 sec(s) Train Acc: 0.207328 Loss: 2.206644 | Val Acc: 0.197668 loss: 2.243790\n",
      "[143/200] 42.06 sec(s) Train Acc: 0.207784 Loss: 2.206046 | Val Acc: 0.169096 loss: 2.384679\n",
      "[144/200] 41.74 sec(s) Train Acc: 0.208798 Loss: 2.204221 | Val Acc: 0.177551 loss: 2.291843\n",
      "[145/200] 41.69 sec(s) Train Acc: 0.208646 Loss: 2.200601 | Val Acc: 0.145481 loss: 2.437528\n",
      "[146/200] 41.68 sec(s) Train Acc: 0.211028 Loss: 2.200472 | Val Acc: 0.189504 loss: 2.250909\n",
      "[147/200] 41.91 sec(s) Train Acc: 0.190097 Loss: 2.238632 | Val Acc: 0.155394 loss: 2.329128\n",
      "[148/200] 41.89 sec(s) Train Acc: 0.190503 Loss: 2.228467 | Val Acc: 0.156560 loss: 2.312705\n",
      "[149/200] 41.83 sec(s) Train Acc: 0.194810 Loss: 2.224356 | Val Acc: 0.147522 loss: 2.374271\n",
      "[150/200] 42.02 sec(s) Train Acc: 0.182242 Loss: 2.254922 | Val Acc: 0.175802 loss: 2.272655\n",
      "[151/200] 42.18 sec(s) Train Acc: 0.186448 Loss: 2.245545 | Val Acc: 0.179592 loss: 2.257937\n",
      "[152/200] 41.67 sec(s) Train Acc: 0.189337 Loss: 2.239112 | Val Acc: 0.191837 loss: 2.231953\n",
      "[153/200] 41.58 sec(s) Train Acc: 0.173880 Loss: 2.263930 | Val Acc: 0.186589 loss: 2.251400\n",
      "[154/200] 41.38 sec(s) Train Acc: 0.182242 Loss: 2.253693 | Val Acc: 0.186297 loss: 2.248932\n",
      "[155/200] 41.15 sec(s) Train Acc: 0.182090 Loss: 2.239108 | Val Acc: 0.187464 loss: 2.235337\n",
      "[156/200] 41.06 sec(s) Train Acc: 0.190452 Loss: 2.230227 | Val Acc: 0.153061 loss: 2.256353\n",
      "[157/200] 41.28 sec(s) Train Acc: 0.190047 Loss: 2.226988 | Val Acc: 0.186880 loss: 2.246960\n",
      "[158/200] 41.21 sec(s) Train Acc: 0.193898 Loss: 2.223334 | Val Acc: 0.167347 loss: 2.298340\n",
      "[159/200] 41.06 sec(s) Train Acc: 0.194253 Loss: 2.217599 | Val Acc: 0.184840 loss: 2.233323\n",
      "[160/200] 41.21 sec(s) Train Acc: 0.197091 Loss: 2.219492 | Val Acc: 0.188047 loss: 2.225075\n",
      "[161/200] 41.11 sec(s) Train Acc: 0.197801 Loss: 2.214075 | Val Acc: 0.179883 loss: 2.264841\n",
      "[162/200] 41.11 sec(s) Train Acc: 0.195013 Loss: 2.221528 | Val Acc: 0.186006 loss: 2.246511\n",
      "[163/200] 41.09 sec(s) Train Acc: 0.192834 Loss: 2.221866 | Val Acc: 0.175219 loss: 2.238460\n",
      "[164/200] 41.13 sec(s) Train Acc: 0.192631 Loss: 2.221598 | Val Acc: 0.118367 loss: 2.623153\n",
      "[165/200] 41.35 sec(s) Train Acc: 0.194912 Loss: 2.220330 | Val Acc: 0.179592 loss: 2.232303\n",
      "[166/200] 41.25 sec(s) Train Acc: 0.194202 Loss: 2.215203 | Val Acc: 0.179883 loss: 2.223606\n",
      "[167/200] 40.99 sec(s) Train Acc: 0.196888 Loss: 2.215717 | Val Acc: 0.177551 loss: 2.240115\n",
      "[168/200] 41.01 sec(s) Train Acc: 0.195419 Loss: 2.215317 | Val Acc: 0.166764 loss: 2.413848\n",
      "[169/200] 40.97 sec(s) Train Acc: 0.194608 Loss: 2.213057 | Val Acc: 0.167930 loss: 2.369412\n",
      "[170/200] 40.95 sec(s) Train Acc: 0.189692 Loss: 2.227427 | Val Acc: 0.122449 loss: 3.316565\n",
      "[171/200] 41.08 sec(s) Train Acc: 0.186296 Loss: 2.232846 | Val Acc: 0.170845 loss: 2.240887\n",
      "[172/200] 41.17 sec(s) Train Acc: 0.189337 Loss: 2.228291 | Val Acc: 0.162391 loss: 2.250370\n",
      "[173/200] 40.95 sec(s) Train Acc: 0.187715 Loss: 2.226509 | Val Acc: 0.152187 loss: 2.298181\n",
      "[174/200] 40.93 sec(s) Train Acc: 0.192175 Loss: 2.225501 | Val Acc: 0.152187 loss: 2.323564\n",
      "[175/200] 40.99 sec(s) Train Acc: 0.189185 Loss: 2.222061 | Val Acc: 0.179883 loss: 2.273180\n",
      "[176/200] 40.92 sec(s) Train Acc: 0.193239 Loss: 2.221859 | Val Acc: 0.178134 loss: 2.266128\n",
      "[177/200] 41.00 sec(s) Train Acc: 0.192631 Loss: 2.219127 | Val Acc: 0.141983 loss: 2.345543\n",
      "[178/200] 41.10 sec(s) Train Acc: 0.192986 Loss: 2.218688 | Val Acc: 0.148397 loss: 2.463125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179/200] 41.09 sec(s) Train Acc: 0.197192 Loss: 2.218909 | Val Acc: 0.203207 loss: 2.226622\n",
      "[180/200] 41.05 sec(s) Train Acc: 0.193442 Loss: 2.220714 | Val Acc: 0.156851 loss: 2.381394\n",
      "[181/200] 40.98 sec(s) Train Acc: 0.192783 Loss: 2.216777 | Val Acc: 0.158017 loss: 2.258715\n",
      "[182/200] 40.99 sec(s) Train Acc: 0.197496 Loss: 2.214475 | Val Acc: 0.133236 loss: 2.683775\n",
      "[183/200] 41.04 sec(s) Train Acc: 0.197142 Loss: 2.213842 | Val Acc: 0.160350 loss: 2.247798\n",
      "[184/200] 41.08 sec(s) Train Acc: 0.198105 Loss: 2.213617 | Val Acc: 0.164140 loss: 2.310762\n",
      "[185/200] 40.94 sec(s) Train Acc: 0.196990 Loss: 2.211659 | Val Acc: 0.156268 loss: 2.388533\n",
      "[186/200] 40.97 sec(s) Train Acc: 0.198713 Loss: 2.210979 | Val Acc: 0.165015 loss: 2.287943\n",
      "[187/200] 41.23 sec(s) Train Acc: 0.198611 Loss: 2.211056 | Val Acc: 0.154227 loss: 2.389191\n",
      "[188/200] 41.01 sec(s) Train Acc: 0.195419 Loss: 2.214052 | Val Acc: 0.157143 loss: 2.366946\n",
      "[189/200] 41.06 sec(s) Train Acc: 0.194557 Loss: 2.212299 | Val Acc: 0.160933 loss: 2.265676\n",
      "[190/200] 40.98 sec(s) Train Acc: 0.201399 Loss: 2.209082 | Val Acc: 0.139359 loss: 2.389112\n",
      "[191/200] 40.83 sec(s) Train Acc: 0.194506 Loss: 2.210567 | Val Acc: 0.144315 loss: 2.815757\n",
      "[192/200] 41.05 sec(s) Train Acc: 0.199524 Loss: 2.209233 | Val Acc: 0.146647 loss: 2.361143\n",
      "[193/200] 40.97 sec(s) Train Acc: 0.199726 Loss: 2.210258 | Val Acc: 0.178426 loss: 2.241089\n",
      "[194/200] 41.23 sec(s) Train Acc: 0.200892 Loss: 2.208818 | Val Acc: 0.156560 loss: 2.490996\n",
      "[195/200] 41.07 sec(s) Train Acc: 0.202868 Loss: 2.208369 | Val Acc: 0.176385 loss: 2.326615\n",
      "[196/200] 41.12 sec(s) Train Acc: 0.200892 Loss: 2.205366 | Val Acc: 0.205539 loss: 2.239507\n",
      "[197/200] 41.00 sec(s) Train Acc: 0.199321 Loss: 2.209245 | Val Acc: 0.177259 loss: 2.291868\n",
      "[198/200] 41.08 sec(s) Train Acc: 0.200639 Loss: 2.210554 | Val Acc: 0.153353 loss: 2.372868\n",
      "[199/200] 40.93 sec(s) Train Acc: 0.202818 Loss: 2.202695 | Val Acc: 0.184257 loss: 2.266238\n",
      "[200/200] 40.98 sec(s) Train Acc: 0.204085 Loss: 2.206020 | Val Acc: 0.168222 loss: 2.352363\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 200\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    student_net.train()\n",
    "    train_loss, train_acc = run_epoch(train_loader, update=True, alpha=0)\n",
    "    student_net.eval()\n",
    "    valid_loss, valid_acc = run_epoch(val_loader, update=False, alpha=0)\n",
    "\n",
    "    # 存下最好的model。\n",
    "    if valid_acc > now_best_acc:\n",
    "        now_best_acc = valid_acc\n",
    "        torch.save(student_net.state_dict(), 'student_model_long.bin')\n",
    "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \n",
    "            (epoch + 1, num_epoch, time.time()-epoch_start_time, train_acc,\n",
    "            train_loss, valid_acc, valid_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
