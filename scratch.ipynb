{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkYS9CnIGmHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-atKwH4GmHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "IN_IPYTHON = True\n",
        "try:\n",
        "    __IPYTHON__\n",
        "except NameError:\n",
        "    IN_IPYTHON = False\n",
        "\n",
        "if IN_IPYTHON:\n",
        "    workspace_dir, output_fpath = 'food-11', 'predict.csv'\n",
        "else:\n",
        "    try:\n",
        "        workspace_dir = sys.argv[1]\n",
        "    except:\n",
        "        workspace_dir = 'food-11'\n",
        "\n",
        "    try:\n",
        "        output_fpath = sys.argv[2]\n",
        "    except:\n",
        "        output_fpath = \"predict.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ipF5ASRGmHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "class StudentNet(nn.Module):\n",
        "    '''\n",
        "      在這個Net裡面，我們會使用Depthwise & Pointwise Convolution Layer來疊model。\n",
        "      你會發現，將原本的Convolution Layer換成Dw & Pw後，Accuracy通常不會降很多。\n",
        "\n",
        "      另外，取名為StudentNet是因為這個Model等會要做Knowledge Distillation。\n",
        "    '''\n",
        "\n",
        "    def __init__(self, base=16, width_mult=1):\n",
        "        '''\n",
        "          Args:\n",
        "            base: 這個model一開始的ch數量，每過一層都會*2，直到base*16為止。\n",
        "            width_mult: 為了之後的Network Pruning使用，在base*8 chs的Layer上會 * width_mult代表剪枝後的ch數量。        \n",
        "        '''\n",
        "        super(StudentNet, self).__init__()\n",
        "        multiplier = [1, 2, 4, 8, 16, 16, 16, 16]\n",
        "\n",
        "        # bandwidth: 每一層Layer所使用的ch數量\n",
        "        bandwidth = [ base * m for m in multiplier]\n",
        "\n",
        "        # 我們只Pruning第三層以後的Layer\n",
        "        for i in range(3, 7):\n",
        "            bandwidth[i] = int(bandwidth[i] * width_mult)\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            # 第一層我們通常不會拆解Convolution Layer。\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(3, bandwidth[0], 3, 1, 1),\n",
        "                nn.BatchNorm2d(bandwidth[0]),\n",
        "                nn.ReLU6(),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "            # 接下來每一個Sequential Block都一樣，所以我們只講一個Block\n",
        "            nn.Sequential(\n",
        "                # Depthwise Convolution\n",
        "                nn.Conv2d(bandwidth[0], bandwidth[0], 3, 1, 1, groups=bandwidth[0]),\n",
        "                # Batch Normalization\n",
        "                nn.BatchNorm2d(bandwidth[0]),\n",
        "                # ReLU6 是限制Neuron最小只會到0，最大只會到6。 MobileNet系列都是使用ReLU6。\n",
        "                # 使用ReLU6的原因是因為如果數字太大，會不好壓到float16 / or further qunatization，因此才給個限制。\n",
        "                nn.ReLU6(),\n",
        "                # Pointwise Convolution\n",
        "                nn.Conv2d(bandwidth[0], bandwidth[1], 1),\n",
        "                # 過完Pointwise Convolution不需要再做ReLU，經驗上Pointwise + ReLU效果都會變差。\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "                # 每過完一個Block就Down Sampling\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[1], bandwidth[1], 3, 1, 1, groups=bandwidth[1]),\n",
        "                nn.BatchNorm2d(bandwidth[1]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[1], bandwidth[2], 1),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[2], bandwidth[2], 3, 1, 1, groups=bandwidth[2]),\n",
        "                nn.BatchNorm2d(bandwidth[2]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[2], bandwidth[3], 1),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "\n",
        "            # 到這邊為止因為圖片已經被Down Sample很多次了，所以就不做MaxPool\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[3], bandwidth[3], 3, 1, 1, groups=bandwidth[3]),\n",
        "                nn.BatchNorm2d(bandwidth[3]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[3], bandwidth[4], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[4], bandwidth[4], 3, 1, 1, groups=bandwidth[4]),\n",
        "                nn.BatchNorm2d(bandwidth[4]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[5], bandwidth[5], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[5], bandwidth[5], 3, 1, 1, groups=bandwidth[5]),\n",
        "                nn.BatchNorm2d(bandwidth[5]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[6], bandwidth[6], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[6], bandwidth[6], 3, 1, 1, groups=bandwidth[6]),\n",
        "                nn.BatchNorm2d(bandwidth[6]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[6], bandwidth[7], 1),\n",
        "            ),\n",
        "\n",
        "            # 這邊我們採用Global Average Pooling。\n",
        "            # 如果輸入圖片大小不一樣的話，就會因為Global Average Pooling壓成一樣的形狀，這樣子接下來做FC就不會對不起來。\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # 這邊我們直接Project到11維輸出答案。\n",
        "            nn.Linear(bandwidth[7], 11),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return self.fc(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MP7YANtGmHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "IMAGE_SIZE = 192\n",
        "def readfile(path, label):\n",
        "    # label 是一個 boolean variable，代表需不需要回傳 y 值\n",
        "    image_dir = sorted(os.listdir(path))\n",
        "    x = np.zeros((len(image_dir), IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.uint8)\n",
        "    y = np.zeros((len(image_dir)), dtype=np.uint8)\n",
        "    for i, file in enumerate(image_dir):\n",
        "        img = cv2.imread(os.path.join(path, file))\n",
        "        # resize to IMAGE_SIZE x ? or ? x IMAGE_SIZE\n",
        "        height = img.shape[0]\n",
        "        width = img.shape[1]\n",
        "        rate = IMAGE_SIZE / max(height, width)\n",
        "        height = int(height * rate)\n",
        "        width = int(width * rate)\n",
        "        img = cv2.resize(img, (width, height))\n",
        "        # pad black\n",
        "        # from https://blog.csdn.net/qq_20622615/article/details/80929746\n",
        "        W, H = IMAGE_SIZE, IMAGE_SIZE\n",
        "        top = (H - height) // 2\n",
        "        bottom = (H - height) // 2\n",
        "        if top + bottom + height < H:\n",
        "            bottom += 1\n",
        "        left = (W - width) // 2\n",
        "        right = (W - width) // 2\n",
        "        if left + right + width < W:\n",
        "            right += 1\n",
        "        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
        "        # to np array\n",
        "        x[i, :, :] = img\n",
        "        if label:\n",
        "            y[i] = int(file.split(\"_\")[0])\n",
        "    if label:\n",
        "      return x, y\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtXR-Wf1GmHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform_mean = np.array([ 69.58238342,  92.66689336, 115.24940137]) / 255\n",
        "transform_std = np.array([71.8342021 , 76.83536755, 83.40123168]) / 255\n",
        "\n",
        "train_transform1 = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomChoice([\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomPerspective()\n",
        "    ]),\n",
        "    transforms.RandomChoice([\n",
        "        transforms.RandomAffine(10), # 隨機線性轉換\n",
        "        transforms.RandomRotation(40)\n",
        "    ]),\n",
        "    transforms.ColorJitter(), # 隨機色溫等\n",
        "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization)\n",
        "    transforms.Normalize(\n",
        "        transform_mean,\n",
        "        transform_std\n",
        "    )\n",
        "])\n",
        "train_transform2 = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomOrder([\n",
        "        transforms.RandomChoice([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomPerspective()\n",
        "        ]),\n",
        "        transforms.RandomAffine(30), # 隨機線性轉換\n",
        "        transforms.RandomResizedCrop((IMAGE_SIZE, IMAGE_SIZE), scale=(0.5, 1.0)), # 隨機子圖\n",
        "    ]),\n",
        "    transforms.RandomChoice([\n",
        "        transforms.ColorJitter(), # 隨機色溫等\n",
        "        transforms.RandomGrayscale(),\n",
        "    ]),\n",
        "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization)\n",
        "    transforms.RandomErasing(0.2),\n",
        "    transforms.Normalize(\n",
        "        transform_mean,\n",
        "        transform_std\n",
        "    )\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),                                    \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        transform_mean,\n",
        "        transform_std\n",
        "    )\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPkHsfTHGmHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
        "\n",
        "class ImgDataset(Dataset):\n",
        "    def __init__(self, x, y=None, transform=None):\n",
        "        self.x = x\n",
        "        # label is required to be a LongTensor\n",
        "        self.y = y\n",
        "        if y is not None:\n",
        "            self.y = torch.LongTensor(y)\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    def __getitem__(self, index):\n",
        "        X = self.x[index]\n",
        "        if self.transform is not None:\n",
        "            X = self.transform(X)\n",
        "        if self.y is not None:\n",
        "            Y = self.y[index]\n",
        "            return X, Y\n",
        "        else:\n",
        "            return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFjUSeuyGmHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "779cda81-7966-4aef-c561-469670dfb232"
      },
      "source": [
        "print(\"Reading data\")\n",
        "train_x, train_y = readfile(os.path.join(workspace_dir, \"training\"), True)\n",
        "print(\"Size of training data = {}\".format(len(train_x)))\n",
        "val_x, val_y = readfile(os.path.join(workspace_dir, \"validation\"), True)\n",
        "print(\"Size of validation data = {}\".format(len(val_x)))\n",
        "\n",
        "batch_size = 32\n",
        "train_set = ConcatDataset([\n",
        "    ImgDataset(train_x, train_y, train_transform1),\n",
        "    ImgDataset(train_x, train_y, train_transform2),\n",
        "    ImgDataset(train_x, train_y, test_transform),\n",
        "#     ImgDataset(val_x, val_y, train_transform1),\n",
        "#     ImgDataset(val_x, val_y, train_transform2),\n",
        "#     ImgDataset(val_x, val_y, test_transform)\n",
        "])\n",
        "val_set = ImgDataset(val_x, val_y, test_transform)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=(16 if os.name=='posix' else 0))\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=(16 if os.name=='posix' else 0))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading data\n",
            "Size of training data = 9866\n",
            "Size of validation data = 3430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_jdro3uGmHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CALCULATE_STD_MEAN = False\n",
        "if CALCULATE_STD_MEAN:\n",
        "    tmp = ConcatDataset([train_set, val_set])\n",
        "    tot, tot2 = np.zeros(3), np.zeros(3)\n",
        "    tot_n = len(tmp) * IMAGE_SIZE ** 2\n",
        "    for x, y in tmp:\n",
        "        x = np.array(x, dtype=np.float64)\n",
        "        tot += x.sum(axis=(0,1))\n",
        "        tot2 += (x*x).sum(axis=(0,1))\n",
        "    tot /= tot_n\n",
        "    tot2 /= tot_n\n",
        "    tot, np.sqrt(tot2 - tot*tot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyzcvatmGmHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TeacherNet_oToToT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TeacherNet_oToToT, self).__init__()\n",
        "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
        "        # input 維度 [3, IMAGE_SIZE, IMAGE_SIZE]\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),\n",
        "            \n",
        "            nn.Dropout(0.4),\n",
        "            \n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),\n",
        "            \n",
        "            nn.Dropout(0.4),\n",
        "            \n",
        "            nn.Conv2d(128, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),\n",
        "            \n",
        "            nn.Dropout(0.4),\n",
        "            \n",
        "            nn.Conv2d(256, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(12*12*512, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.Dropout(0.4),\n",
        "            \n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "                        \n",
        "            nn.Linear(1024, 11)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return self.fc(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v29a5rjiGmHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_net = TeacherNet_oToToT().cuda()\n",
        "# teacher_net.load_state_dict(torch.load('teacher_model.bin'))\n",
        "loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
        "optimizers = [\n",
        "    (torch.optim.Adam, 0.002),\n",
        "    (torch.optim.SGD, 0.001)\n",
        "]\n",
        "num_epochs = [\n",
        "    80,\n",
        "    250\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fA-puxSEGmHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "TRAIN_TEACHER_NET = False\n",
        "\n",
        "if TRAIN_TEACHER_NET:\n",
        "    best_acc = 0\n",
        "\n",
        "    for (optimizer, lr), num_epoch in zip(optimizers, num_epochs):\n",
        "        optimizer = optimizer(teacher_net.parameters(), lr)\n",
        "        for epoch in range(num_epoch):\n",
        "            epoch_start_time = time.time()\n",
        "            train_acc = 0.0\n",
        "            train_loss = 0.0\n",
        "            val_acc = 0.0\n",
        "            val_loss = 0.0\n",
        "\n",
        "            teacher_net.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
        "            for i, data in enumerate(train_loader):\n",
        "                optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
        "                train_pred = teacher_net(data[0].cuda()) # 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
        "                batch_loss = loss(train_pred, data[1].cuda()) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
        "                batch_loss.backward() \n",
        "                optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
        "\n",
        "                train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "                train_loss += batch_loss.item()\n",
        "\n",
        "#             print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f' % \n",
        "#                 (epoch + 1, num_epoch, time.time()-epoch_start_time, train_acc/len(train_set), train_loss/len(train_set)))\n",
        "                \n",
        "            teacher_net.eval()\n",
        "            with torch.no_grad():\n",
        "                for i, data in enumerate(val_loader):\n",
        "                    val_pred = teacher_net(data[0].cuda())\n",
        "                    batch_loss = loss(val_pred, data[1].cuda())\n",
        "                    val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "                    val_loss += batch_loss.item()\n",
        "\n",
        "                if val_acc > best_acc:\n",
        "                    torch.save(teacher_net.state_dict(), 'teacher_model.bin')\n",
        "\n",
        "                #將結果 print 出來\n",
        "                print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \n",
        "                      (epoch + 1, num_epoch, time.time()-epoch_start_time, train_acc/len(train_set),\n",
        "                       train_loss/len(train_set), val_acc/len(val_set), val_loss/len(val_set)))\n",
        "#     torch.save(teacher_net.state_dict(), 'teacher_model.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrRyhJaiGmHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_net = TeacherNet_oToToT().cuda()\n",
        "# teacher_net.load_state_dict(torch.load('teacher_model.bin'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVjxbBs5GmHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CHECK_TEACHER_NET = False\n",
        "if CHECK_TEACHER_NET:\n",
        "    test_x = readfile(os.path.join(workspace_dir, \"testing\"), False)\n",
        "    print(\"Size of Testing data = {}\".format(len(test_x)))\n",
        "    test_set = ImgDataset(test_x, transform=test_transform)\n",
        "    test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=(16 if os.name=='posix' else 0))\n",
        "\n",
        "    teacher_net.eval()\n",
        "\n",
        "    prediction = []\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader):\n",
        "            test_pred = teacher_net(data.cuda())\n",
        "            test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
        "            for y in test_label:\n",
        "                prediction.append(y)\n",
        "\n",
        "    with open(output_fpath, 'w') as f:\n",
        "        f.write('Id,Category\\n')\n",
        "        for i, y in enumerate(prediction):\n",
        "            f.write('{},{}\\n'.format(i, y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFePu3O2GmHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class swish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(swish, self).__init__()\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = x * F.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class StudentNet(nn.Module):\n",
        "    '''\n",
        "      在這個Net裡面，我們會使用Depthwise & Pointwise Convolution Layer來疊model。\n",
        "      你會發現，將原本的Convolution Layer換成Dw & Pw後，Accuracy通常不會降很多。\n",
        "\n",
        "      另外，取名為StudentNet是因為這個Model等會要做Knowledge Distillation。\n",
        "    '''\n",
        "\n",
        "    def __init__(self, base=16, width_mult=1):\n",
        "        '''\n",
        "          Args:\n",
        "            base: 這個model一開始的ch數量，每過一層都會*2，直到base*16為止。\n",
        "            width_mult: 為了之後的Network Pruning使用，在base*8 chs的Layer上會 * width_mult代表剪枝後的ch數量。        \n",
        "        '''\n",
        "        super(StudentNet, self).__init__()\n",
        "        multiplier = [2, 4, 8, 8, 8, 16, 16, 16, 16]\n",
        "\n",
        "        # bandwidth: 每一層Layer所使用的ch數量\n",
        "        bandwidth = [int(base * m) for m in multiplier]\n",
        "\n",
        "        # 我們只Pruning第三層以後的Layer\n",
        "        for i in range(4, 8):\n",
        "            bandwidth[i] = int(bandwidth[i] * width_mult)\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            # 第一層我們通常不會拆解Convolution Layer。\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(3, bandwidth[0], 3, 1, 1),\n",
        "                nn.BatchNorm2d(bandwidth[0]),\n",
        "                nn.ReLU6(),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "            # 接下來每一個Sequential Block都一樣，所以我們只講一個Block\n",
        "            nn.Sequential(\n",
        "                # Depthwise Convolution\n",
        "                nn.Conv2d(bandwidth[0], bandwidth[0], 3, 1, 1, groups=bandwidth[0]),\n",
        "                # Batch Normalization\n",
        "                nn.BatchNorm2d(bandwidth[0]),\n",
        "                # ReLU6 是限制Neuron最小只會到0，最大只會到6。 MobileNet系列都是使用ReLU6。\n",
        "                # 使用ReLU6的原因是因為如果數字太大，會不好壓到float16 / or further qunatization，因此才給個限制。\n",
        "                nn.ReLU6(),\n",
        "                # Pointwise Convolution\n",
        "                nn.Conv2d(bandwidth[0], bandwidth[1], 1),\n",
        "                # 過完Pointwise Convolution不需要再做ReLU，經驗上Pointwise + ReLU效果都會變差。\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "                # 每過完一個Block就Down Sampling\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[1], bandwidth[1], 3, 1, 1, groups=bandwidth[1]),\n",
        "                nn.BatchNorm2d(bandwidth[1]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[1], bandwidth[2], 1),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[2], bandwidth[2], 3, 1, 1, groups=bandwidth[2]),\n",
        "                nn.BatchNorm2d(bandwidth[2]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[2], bandwidth[3], 1),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "            \n",
        "            # 到這邊為止因為圖片已經被Down Sample很多次了，所以就不做MaxPool\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[3], bandwidth[3], 3, 1, 1, groups=bandwidth[3]),\n",
        "                nn.BatchNorm2d(bandwidth[3]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[3], bandwidth[4], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[4], bandwidth[4], 3, 1, 1, groups=bandwidth[4]),\n",
        "                nn.BatchNorm2d(bandwidth[4]),\n",
        "                swish(),\n",
        "                nn.Conv2d(bandwidth[4], bandwidth[5], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[5], bandwidth[5], 3, 1, 1, groups=bandwidth[5]),\n",
        "                nn.BatchNorm2d(bandwidth[5]),\n",
        "                swish(),\n",
        "                nn.Conv2d(bandwidth[5], bandwidth[6], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[6], bandwidth[6], 3, 1, 1, groups=bandwidth[6]),\n",
        "                nn.BatchNorm2d(bandwidth[6]),\n",
        "                swish(),\n",
        "                nn.Conv2d(bandwidth[6], bandwidth[7], 1),\n",
        "            ),\n",
        "            \n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[7], bandwidth[7], 3, 1, 1, groups=bandwidth[7]),\n",
        "                nn.BatchNorm2d(bandwidth[7]),\n",
        "                swish(),\n",
        "                nn.Conv2d(bandwidth[7], bandwidth[8], 1),\n",
        "            ),\n",
        "\n",
        "            # 這邊我們採用Global Average Pooling。\n",
        "            # 如果輸入圖片大小不一樣的話，就會因為Global Average Pooling壓成一樣的形狀，這樣子接下來做FC就不會對不起來。\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # 這邊我們直接Project到11維輸出答案。\n",
        "            nn.Linear(bandwidth[8], 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU6(),\n",
        "            \n",
        "            nn.Dropout(0.4),\n",
        "            \n",
        "            nn.Linear(128, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            swish(),\n",
        "                        \n",
        "            nn.Linear(128, 11)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return self.fc(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vVeipg5GmHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn_kd(outputs, labels, teacher_outputs, T=20, alpha=0.5):\n",
        "    # 一般的Cross Entropy\n",
        "    hard_loss = F.cross_entropy(outputs, labels) * (1. - alpha)\n",
        "    # 讓logits的log_softmax對目標機率(teacher的logits/T後softmax)做KL Divergence。\n",
        "    soft_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs/T, dim=1),\n",
        "                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T)\n",
        "    return hard_loss + soft_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf1O2B20GmHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from torchvision.models import mobilenet_v2\n",
        "# student_net = mobilenet_v2(\n",
        "#     num_classes=11,\n",
        "#     width_mult=0.6,\n",
        "#     round_nearest=4,\n",
        "#     inverted_residual_setting = [\n",
        "#         # t, c, n, s\n",
        "#         [1, 16, 1, 1],\n",
        "#         [6, 24, 2, 2],\n",
        "# #         [6, 32, 3, 2],\n",
        "#         [6, 64, 4, 2],\n",
        "#         [6, 96, 3, 1],\n",
        "# #         [6, 160, 3, 2],\n",
        "#         [6, 320, 1, 1],\n",
        "#     ]\n",
        "# ).cuda()\n",
        "\n",
        "student_net_base = 9.5\n",
        "student_net = StudentNet(student_net_base).cuda()\n",
        "# student_net.load_state_dict(torch.load('student_model.bin'))\n",
        "\n",
        "optimizer = torch.optim.Adam(student_net.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJzVNqWdGmHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_epoch(dataloader, update=True, alpha=0.5):\n",
        "    total_num, total_hit, total_loss = 0, 0, 0\n",
        "    for now_step, batch_data in enumerate(dataloader):\n",
        "        # 清空 optimizer\n",
        "        optimizer.zero_grad()\n",
        "        # 處理 input\n",
        "        inputs, hard_labels = batch_data\n",
        "        inputs = inputs.cuda()\n",
        "        hard_labels = torch.LongTensor(hard_labels).cuda()\n",
        "        # 因為Teacher沒有要backprop，所以我們使用torch.no_grad\n",
        "        # 告訴torch不要暫存中間值(去做backprop)以浪費記憶體空間。\n",
        "        with torch.no_grad():\n",
        "            soft_labels = teacher_net(inputs)\n",
        "\n",
        "        if update:\n",
        "            logits = student_net(inputs)\n",
        "            # 使用我們之前所寫的融合soft label&hard label的loss。\n",
        "            # T=20是原始論文的參數設定。\n",
        "            loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n",
        "            loss.backward()\n",
        "            optimizer.step()    \n",
        "        else:\n",
        "            # 只是算validation acc的話，就開no_grad節省空間。\n",
        "            with torch.no_grad():\n",
        "                logits = student_net(inputs)\n",
        "                loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n",
        "            \n",
        "        total_hit += torch.sum(torch.argmax(logits, dim=1) == hard_labels).item()\n",
        "        total_num += len(inputs)\n",
        "\n",
        "        total_loss += loss.item() * len(inputs)\n",
        "    return total_loss / total_num, total_hit / total_num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "AqZZEoAKGmH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epoch = 0\n",
        "\n",
        "# TeacherNet永遠都是Eval mode.\n",
        "teacher_net.eval()\n",
        "now_best_acc = 0\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time = time.time()\n",
        "    \n",
        "    student_net.train()\n",
        "    train_loss, train_acc = run_epoch(train_loader, update=True)\n",
        "    student_net.eval()\n",
        "    valid_loss, valid_acc = run_epoch(val_loader, update=False)\n",
        "\n",
        "    # 存下最好的model。\n",
        "    if valid_acc > now_best_acc:\n",
        "        now_best_acc = valid_acc\n",
        "        torch.save(student_net.state_dict(), 'student_model.bin')\n",
        "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \n",
        "            (epoch + 1, num_epoch, time.time()-epoch_start_time, train_acc,\n",
        "            train_loss, valid_acc, valid_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTuZkRwaGmH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98e09589-fcbf-4a1f-ea9d-6204e46f2674"
      },
      "source": [
        "num_epoch = 200\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time = time.time()\n",
        "    \n",
        "    student_net.train()\n",
        "    train_loss, train_acc = run_epoch(train_loader, update=True, alpha=0)\n",
        "    student_net.eval()\n",
        "    valid_loss, valid_acc = run_epoch(val_loader, update=False, alpha=0)\n",
        "\n",
        "    # 存下最好的model。\n",
        "    if valid_acc > now_best_acc:\n",
        "        now_best_acc = valid_acc\n",
        "        torch.save(student_net.state_dict(), 'student_model.bin')\n",
        "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \n",
        "            (epoch + 1, num_epoch, time.time()-epoch_start_time, train_acc,\n",
        "            train_loss, valid_acc, valid_loss))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[001/200] 118.98 sec(s) Train Acc: 0.378032 Loss: 1.785778 | Val Acc: 0.474927 loss: 1.495233\n",
            "[002/200] 119.97 sec(s) Train Acc: 0.501047 Loss: 1.451552 | Val Acc: 0.555685 loss: 1.304203\n",
            "[003/200] 119.40 sec(s) Train Acc: 0.560139 Loss: 1.293410 | Val Acc: 0.609038 loss: 1.151098\n",
            "[004/200] 119.34 sec(s) Train Acc: 0.601730 Loss: 1.176271 | Val Acc: 0.632362 loss: 1.089287\n",
            "[005/200] 119.38 sec(s) Train Acc: 0.629367 Loss: 1.096457 | Val Acc: 0.633236 loss: 1.101039\n",
            "[006/200] 119.31 sec(s) Train Acc: 0.650720 Loss: 1.032368 | Val Acc: 0.662391 loss: 0.992124\n",
            "[007/200] 119.30 sec(s) Train Acc: 0.669843 Loss: 0.972764 | Val Acc: 0.665889 loss: 0.995250\n",
            "[008/200] 118.98 sec(s) Train Acc: 0.692175 Loss: 0.915369 | Val Acc: 0.680175 loss: 0.955115\n",
            "[009/200] 118.98 sec(s) Train Acc: 0.709001 Loss: 0.881906 | Val Acc: 0.655977 loss: 1.035984\n",
            "[010/200] 118.85 sec(s) Train Acc: 0.719576 Loss: 0.843254 | Val Acc: 0.684548 loss: 0.944667\n",
            "[011/200] 118.54 sec(s) Train Acc: 0.728259 Loss: 0.808361 | Val Acc: 0.689213 loss: 0.949817\n",
            "[012/200] 119.06 sec(s) Train Acc: 0.741199 Loss: 0.782177 | Val Acc: 0.688047 loss: 0.981630\n",
            "[013/200] 118.89 sec(s) Train Acc: 0.750186 Loss: 0.748123 | Val Acc: 0.700292 loss: 0.925438\n",
            "[014/200] 118.72 sec(s) Train Acc: 0.758126 Loss: 0.732133 | Val Acc: 0.702624 loss: 0.910365\n",
            "[015/200] 118.72 sec(s) Train Acc: 0.765457 Loss: 0.709722 | Val Acc: 0.712828 loss: 0.942362\n",
            "[016/200] 118.45 sec(s) Train Acc: 0.772485 Loss: 0.682803 | Val Acc: 0.694752 loss: 0.964217\n",
            "[017/200] 118.54 sec(s) Train Acc: 0.779005 Loss: 0.673340 | Val Acc: 0.711662 loss: 0.896392\n",
            "[018/200] 118.27 sec(s) Train Acc: 0.786472 Loss: 0.652489 | Val Acc: 0.708746 loss: 0.906612\n",
            "[019/200] 118.50 sec(s) Train Acc: 0.787756 Loss: 0.641181 | Val Acc: 0.718659 loss: 0.868600\n",
            "[020/200] 118.56 sec(s) Train Acc: 0.794783 Loss: 0.624230 | Val Acc: 0.729446 loss: 0.835926\n",
            "[021/200] 118.35 sec(s) Train Acc: 0.803500 Loss: 0.606649 | Val Acc: 0.734402 loss: 0.884630\n",
            "[022/200] 118.54 sec(s) Train Acc: 0.807318 Loss: 0.590456 | Val Acc: 0.723615 loss: 0.921780\n",
            "[023/200] 118.49 sec(s) Train Acc: 0.810291 Loss: 0.585830 | Val Acc: 0.717493 loss: 0.929125\n",
            "[024/200] 118.57 sec(s) Train Acc: 0.815224 Loss: 0.564069 | Val Acc: 0.737026 loss: 0.873539\n",
            "[025/200] 118.60 sec(s) Train Acc: 0.814751 Loss: 0.564783 | Val Acc: 0.739067 loss: 0.866685\n",
            "[026/200] 118.72 sec(s) Train Acc: 0.821373 Loss: 0.552220 | Val Acc: 0.737609 loss: 0.877674\n",
            "[027/200] 117.65 sec(s) Train Acc: 0.821170 Loss: 0.547970 | Val Acc: 0.723615 loss: 0.882737\n",
            "[028/200] 117.80 sec(s) Train Acc: 0.828907 Loss: 0.529267 | Val Acc: 0.729155 loss: 0.892305\n",
            "[029/200] 117.50 sec(s) Train Acc: 0.829245 Loss: 0.526478 | Val Acc: 0.736735 loss: 0.862925\n",
            "[030/200] 117.89 sec(s) Train Acc: 0.833941 Loss: 0.511648 | Val Acc: 0.728571 loss: 0.910216\n",
            "[031/200] 118.03 sec(s) Train Acc: 0.833671 Loss: 0.513852 | Val Acc: 0.737901 loss: 0.877667\n",
            "[032/200] 117.83 sec(s) Train Acc: 0.838536 Loss: 0.499698 | Val Acc: 0.732362 loss: 0.911874\n",
            "[033/200] 118.11 sec(s) Train Acc: 0.835901 Loss: 0.500602 | Val Acc: 0.742566 loss: 0.860622\n",
            "[034/200] 117.74 sec(s) Train Acc: 0.842489 Loss: 0.485019 | Val Acc: 0.751020 loss: 0.853393\n",
            "[035/200] 117.60 sec(s) Train Acc: 0.843908 Loss: 0.481005 | Val Acc: 0.756268 loss: 0.851596\n",
            "[036/200] 117.98 sec(s) Train Acc: 0.845395 Loss: 0.480201 | Val Acc: 0.736443 loss: 0.905473\n",
            "[037/200] 117.73 sec(s) Train Acc: 0.850530 Loss: 0.467288 | Val Acc: 0.742274 loss: 0.856361\n",
            "[038/200] 117.85 sec(s) Train Acc: 0.850159 Loss: 0.461960 | Val Acc: 0.746939 loss: 0.884038\n",
            "[039/200] 117.78 sec(s) Train Acc: 0.850530 Loss: 0.455792 | Val Acc: 0.734694 loss: 0.898678\n",
            "[040/200] 119.28 sec(s) Train Acc: 0.852997 Loss: 0.460386 | Val Acc: 0.746647 loss: 0.860327\n",
            "[041/200] 118.70 sec(s) Train Acc: 0.857085 Loss: 0.443871 | Val Acc: 0.741691 loss: 0.886646\n",
            "[042/200] 118.54 sec(s) Train Acc: 0.857761 Loss: 0.437612 | Val Acc: 0.744898 loss: 0.880926\n",
            "[043/200] 118.70 sec(s) Train Acc: 0.858876 Loss: 0.434465 | Val Acc: 0.752478 loss: 0.822880\n",
            "[044/200] 118.78 sec(s) Train Acc: 0.861714 Loss: 0.436075 | Val Acc: 0.759475 loss: 0.817483\n",
            "[045/200] 118.33 sec(s) Train Acc: 0.863639 Loss: 0.426720 | Val Acc: 0.752187 loss: 0.858040\n",
            "[046/200] 118.53 sec(s) Train Acc: 0.864957 Loss: 0.420128 | Val Acc: 0.750437 loss: 0.850393\n",
            "[047/200] 118.49 sec(s) Train Acc: 0.864653 Loss: 0.416339 | Val Acc: 0.747522 loss: 0.908599\n",
            "[048/200] 118.78 sec(s) Train Acc: 0.866207 Loss: 0.408016 | Val Acc: 0.754519 loss: 0.874395\n",
            "[049/200] 118.62 sec(s) Train Acc: 0.867221 Loss: 0.412404 | Val Acc: 0.755394 loss: 0.841414\n",
            "[050/200] 118.60 sec(s) Train Acc: 0.866207 Loss: 0.413218 | Val Acc: 0.753353 loss: 0.906364\n",
            "[051/200] 118.31 sec(s) Train Acc: 0.869079 Loss: 0.405001 | Val Acc: 0.751312 loss: 0.895897\n",
            "[052/200] 118.46 sec(s) Train Acc: 0.869518 Loss: 0.410293 | Val Acc: 0.741108 loss: 0.904539\n",
            "[053/200] 118.84 sec(s) Train Acc: 0.868944 Loss: 0.397520 | Val Acc: 0.749271 loss: 0.854306\n",
            "[054/200] 118.64 sec(s) Train Acc: 0.869147 Loss: 0.400311 | Val Acc: 0.746647 loss: 0.914426\n",
            "[055/200] 118.49 sec(s) Train Acc: 0.871849 Loss: 0.397866 | Val Acc: 0.765889 loss: 0.838550\n",
            "[056/200] 118.04 sec(s) Train Acc: 0.875971 Loss: 0.385181 | Val Acc: 0.761224 loss: 0.899001\n",
            "[057/200] 118.53 sec(s) Train Acc: 0.877188 Loss: 0.377555 | Val Acc: 0.754810 loss: 0.911788\n",
            "[058/200] 118.13 sec(s) Train Acc: 0.876850 Loss: 0.381726 | Val Acc: 0.759184 loss: 0.858594\n",
            "[059/200] 118.31 sec(s) Train Acc: 0.879992 Loss: 0.371779 | Val Acc: 0.765306 loss: 0.834014\n",
            "[060/200] 118.38 sec(s) Train Acc: 0.882289 Loss: 0.366262 | Val Acc: 0.757143 loss: 0.892937\n",
            "[061/200] 118.80 sec(s) Train Acc: 0.879012 Loss: 0.375185 | Val Acc: 0.755394 loss: 0.885576\n",
            "[062/200] 118.88 sec(s) Train Acc: 0.884823 Loss: 0.362493 | Val Acc: 0.772595 loss: 0.853463\n",
            "[063/200] 118.80 sec(s) Train Acc: 0.880566 Loss: 0.371760 | Val Acc: 0.754227 loss: 0.887212\n",
            "[064/200] 118.96 sec(s) Train Acc: 0.879823 Loss: 0.368542 | Val Acc: 0.756560 loss: 0.901104\n",
            "[065/200] 118.52 sec(s) Train Acc: 0.883844 Loss: 0.363238 | Val Acc: 0.758309 loss: 0.889066\n",
            "[066/200] 118.30 sec(s) Train Acc: 0.883506 Loss: 0.361189 | Val Acc: 0.769096 loss: 0.841349\n",
            "[067/200] 118.63 sec(s) Train Acc: 0.881512 Loss: 0.368360 | Val Acc: 0.759184 loss: 0.866502\n",
            "[068/200] 118.25 sec(s) Train Acc: 0.883235 Loss: 0.358260 | Val Acc: 0.763557 loss: 0.849099\n",
            "[069/200] 118.39 sec(s) Train Acc: 0.888033 Loss: 0.347562 | Val Acc: 0.766472 loss: 0.851917\n",
            "[070/200] 119.01 sec(s) Train Acc: 0.886276 Loss: 0.356992 | Val Acc: 0.766181 loss: 0.849317\n",
            "[071/200] 118.52 sec(s) Train Acc: 0.887628 Loss: 0.348865 | Val Acc: 0.749563 loss: 0.885162\n",
            "[072/200] 118.66 sec(s) Train Acc: 0.888506 Loss: 0.352614 | Val Acc: 0.769971 loss: 0.830629\n",
            "[073/200] 118.88 sec(s) Train Acc: 0.887121 Loss: 0.349233 | Val Acc: 0.767638 loss: 0.835282\n",
            "[074/200] 118.68 sec(s) Train Acc: 0.891378 Loss: 0.335911 | Val Acc: 0.760933 loss: 0.914533\n",
            "[075/200] 118.42 sec(s) Train Acc: 0.890466 Loss: 0.340576 | Val Acc: 0.768222 loss: 0.856176\n",
            "[076/200] 118.37 sec(s) Train Acc: 0.892898 Loss: 0.333968 | Val Acc: 0.758309 loss: 0.892444\n",
            "[077/200] 118.77 sec(s) Train Acc: 0.891648 Loss: 0.335967 | Val Acc: 0.777259 loss: 0.803302\n",
            "[078/200] 119.02 sec(s) Train Acc: 0.894419 Loss: 0.330055 | Val Acc: 0.774636 loss: 0.833460\n",
            "[079/200] 118.83 sec(s) Train Acc: 0.894013 Loss: 0.331787 | Val Acc: 0.773761 loss: 0.816320\n",
            "[080/200] 118.70 sec(s) Train Acc: 0.894621 Loss: 0.325444 | Val Acc: 0.768805 loss: 0.844383\n",
            "[081/200] 118.61 sec(s) Train Acc: 0.889688 Loss: 0.337742 | Val Acc: 0.774052 loss: 0.822071\n",
            "[082/200] 118.71 sec(s) Train Acc: 0.894587 Loss: 0.324079 | Val Acc: 0.765306 loss: 0.851477\n",
            "[083/200] 119.06 sec(s) Train Acc: 0.899419 Loss: 0.314776 | Val Acc: 0.779009 loss: 0.838856\n",
            "[084/200] 118.78 sec(s) Train Acc: 0.894047 Loss: 0.324378 | Val Acc: 0.760641 loss: 0.874228\n",
            "[085/200] 118.70 sec(s) Train Acc: 0.897358 Loss: 0.322454 | Val Acc: 0.768222 loss: 0.853646\n",
            "[086/200] 118.52 sec(s) Train Acc: 0.895939 Loss: 0.323428 | Val Acc: 0.758309 loss: 0.896695\n",
            "[087/200] 118.43 sec(s) Train Acc: 0.897865 Loss: 0.318529 | Val Acc: 0.769679 loss: 0.877713\n",
            "[088/200] 118.81 sec(s) Train Acc: 0.901547 Loss: 0.307306 | Val Acc: 0.764723 loss: 0.890862\n",
            "[089/200] 118.37 sec(s) Train Acc: 0.895736 Loss: 0.316857 | Val Acc: 0.776093 loss: 0.846643\n",
            "[090/200] 118.52 sec(s) Train Acc: 0.896581 Loss: 0.313423 | Val Acc: 0.769388 loss: 0.880197\n",
            "[091/200] 118.63 sec(s) Train Acc: 0.899149 Loss: 0.311512 | Val Acc: 0.773178 loss: 0.851105\n",
            "[092/200] 118.14 sec(s) Train Acc: 0.898709 Loss: 0.312147 | Val Acc: 0.784548 loss: 0.816756\n",
            "[093/200] 118.47 sec(s) Train Acc: 0.898304 Loss: 0.311626 | Val Acc: 0.768222 loss: 0.869426\n",
            "[094/200] 118.45 sec(s) Train Acc: 0.900770 Loss: 0.309710 | Val Acc: 0.769388 loss: 0.854698\n",
            "[095/200] 118.38 sec(s) Train Acc: 0.903406 Loss: 0.303341 | Val Acc: 0.770262 loss: 0.891891\n",
            "[096/200] 118.82 sec(s) Train Acc: 0.901987 Loss: 0.306781 | Val Acc: 0.773178 loss: 0.878402\n",
            "[097/200] 118.39 sec(s) Train Acc: 0.905129 Loss: 0.299215 | Val Acc: 0.770845 loss: 0.888489\n",
            "[098/200] 118.63 sec(s) Train Acc: 0.906142 Loss: 0.297354 | Val Acc: 0.769971 loss: 0.875351\n",
            "[099/200] 118.88 sec(s) Train Acc: 0.902865 Loss: 0.306151 | Val Acc: 0.765889 loss: 0.869632\n",
            "[100/200] 118.56 sec(s) Train Acc: 0.903000 Loss: 0.300340 | Val Acc: 0.777259 loss: 0.845447\n",
            "[101/200] 118.64 sec(s) Train Acc: 0.902966 Loss: 0.294822 | Val Acc: 0.778134 loss: 0.869307\n",
            "[102/200] 118.77 sec(s) Train Acc: 0.903743 Loss: 0.297650 | Val Acc: 0.773469 loss: 0.871423\n",
            "[103/200] 118.56 sec(s) Train Acc: 0.906582 Loss: 0.294540 | Val Acc: 0.766472 loss: 0.895766\n",
            "[104/200] 118.66 sec(s) Train Acc: 0.905365 Loss: 0.292359 | Val Acc: 0.768805 loss: 0.885502\n",
            "[105/200] 118.56 sec(s) Train Acc: 0.902223 Loss: 0.294938 | Val Acc: 0.767638 loss: 0.877331\n",
            "[106/200] 118.70 sec(s) Train Acc: 0.906480 Loss: 0.293471 | Val Acc: 0.778134 loss: 0.836845\n",
            "[107/200] 118.20 sec(s) Train Acc: 0.906886 Loss: 0.288395 | Val Acc: 0.770845 loss: 0.858517\n",
            "[108/200] 118.72 sec(s) Train Acc: 0.909825 Loss: 0.276026 | Val Acc: 0.772303 loss: 0.873867\n",
            "[109/200] 118.99 sec(s) Train Acc: 0.905365 Loss: 0.287223 | Val Acc: 0.773469 loss: 0.869198\n",
            "[110/200] 118.69 sec(s) Train Acc: 0.906886 Loss: 0.287156 | Val Acc: 0.771137 loss: 0.884206\n",
            "[111/200] 118.89 sec(s) Train Acc: 0.907021 Loss: 0.286658 | Val Acc: 0.769388 loss: 0.880517\n",
            "[112/200] 118.72 sec(s) Train Acc: 0.910061 Loss: 0.276934 | Val Acc: 0.772595 loss: 0.866403\n",
            "[113/200] 118.70 sec(s) Train Acc: 0.905804 Loss: 0.283895 | Val Acc: 0.773761 loss: 0.856930\n",
            "[114/200] 119.02 sec(s) Train Acc: 0.908744 Loss: 0.283358 | Val Acc: 0.781050 loss: 0.849618\n",
            "[115/200] 118.46 sec(s) Train Acc: 0.907528 Loss: 0.282323 | Val Acc: 0.776385 loss: 0.842060\n",
            "[116/200] 119.01 sec(s) Train Acc: 0.910636 Loss: 0.280416 | Val Acc: 0.781924 loss: 0.853525\n",
            "[117/200] 118.90 sec(s) Train Acc: 0.911481 Loss: 0.275186 | Val Acc: 0.774927 loss: 0.918514\n",
            "[118/200] 118.70 sec(s) Train Acc: 0.913204 Loss: 0.273222 | Val Acc: 0.778717 loss: 0.883499\n",
            "[119/200] 118.82 sec(s) Train Acc: 0.908811 Loss: 0.279872 | Val Acc: 0.766472 loss: 0.869414\n",
            "[120/200] 118.92 sec(s) Train Acc: 0.911616 Loss: 0.270212 | Val Acc: 0.781050 loss: 0.880192\n",
            "[121/200] 119.10 sec(s) Train Acc: 0.912764 Loss: 0.269738 | Val Acc: 0.773761 loss: 0.858407\n",
            "[122/200] 119.12 sec(s) Train Acc: 0.913677 Loss: 0.268084 | Val Acc: 0.774052 loss: 0.894103\n",
            "[123/200] 118.84 sec(s) Train Acc: 0.914082 Loss: 0.266843 | Val Acc: 0.772886 loss: 0.902654\n",
            "[124/200] 119.23 sec(s) Train Acc: 0.914352 Loss: 0.272086 | Val Acc: 0.776968 loss: 0.897276\n",
            "[125/200] 118.96 sec(s) Train Acc: 0.917224 Loss: 0.263236 | Val Acc: 0.780466 loss: 0.872060\n",
            "[126/200] 118.94 sec(s) Train Acc: 0.913373 Loss: 0.268346 | Val Acc: 0.775802 loss: 0.881049\n",
            "[127/200] 118.86 sec(s) Train Acc: 0.914859 Loss: 0.264716 | Val Acc: 0.773178 loss: 0.871609\n",
            "[128/200] 118.56 sec(s) Train Acc: 0.912764 Loss: 0.265974 | Val Acc: 0.777551 loss: 0.895655\n",
            "[129/200] 118.91 sec(s) Train Acc: 0.913068 Loss: 0.265554 | Val Acc: 0.776968 loss: 0.874345\n",
            "[130/200] 119.02 sec(s) Train Acc: 0.916616 Loss: 0.256510 | Val Acc: 0.770554 loss: 0.914757\n",
            "[131/200] 118.59 sec(s) Train Acc: 0.915636 Loss: 0.260881 | Val Acc: 0.779009 loss: 0.862528\n",
            "[132/200] 118.85 sec(s) Train Acc: 0.915265 Loss: 0.260876 | Val Acc: 0.781341 loss: 0.890280\n",
            "[133/200] 118.97 sec(s) Train Acc: 0.915096 Loss: 0.260283 | Val Acc: 0.771429 loss: 0.894885\n",
            "[134/200] 118.95 sec(s) Train Acc: 0.914521 Loss: 0.264750 | Val Acc: 0.780758 loss: 0.867305\n",
            "[135/200] 118.86 sec(s) Train Acc: 0.915062 Loss: 0.264913 | Val Acc: 0.778134 loss: 0.865419\n",
            "[136/200] 118.90 sec(s) Train Acc: 0.916785 Loss: 0.254844 | Val Acc: 0.781341 loss: 0.862626\n",
            "[137/200] 119.01 sec(s) Train Acc: 0.916211 Loss: 0.255810 | Val Acc: 0.771137 loss: 0.894842\n",
            "[138/200] 119.42 sec(s) Train Acc: 0.916684 Loss: 0.255330 | Val Acc: 0.772595 loss: 0.914079\n",
            "[139/200] 119.33 sec(s) Train Acc: 0.917765 Loss: 0.257750 | Val Acc: 0.780466 loss: 0.859349\n",
            "[140/200] 119.33 sec(s) Train Acc: 0.918170 Loss: 0.254600 | Val Acc: 0.779592 loss: 0.859655\n",
            "[141/200] 119.26 sec(s) Train Acc: 0.918305 Loss: 0.250503 | Val Acc: 0.778717 loss: 0.862524\n",
            "[142/200] 119.51 sec(s) Train Acc: 0.917697 Loss: 0.253822 | Val Acc: 0.759767 loss: 0.937262\n",
            "[143/200] 119.23 sec(s) Train Acc: 0.917731 Loss: 0.252887 | Val Acc: 0.774344 loss: 0.901490\n",
            "[144/200] 119.09 sec(s) Train Acc: 0.919386 Loss: 0.254911 | Val Acc: 0.783673 loss: 0.858138\n",
            "[145/200] 119.02 sec(s) Train Acc: 0.920130 Loss: 0.247314 | Val Acc: 0.777551 loss: 0.888834\n",
            "[146/200] 119.13 sec(s) Train Acc: 0.918373 Loss: 0.247942 | Val Acc: 0.774344 loss: 0.896796\n",
            "[147/200] 119.28 sec(s) Train Acc: 0.918778 Loss: 0.253145 | Val Acc: 0.776968 loss: 0.887087\n",
            "[148/200] 118.45 sec(s) Train Acc: 0.918981 Loss: 0.247318 | Val Acc: 0.778426 loss: 0.878091\n",
            "[149/200] 118.36 sec(s) Train Acc: 0.920299 Loss: 0.247305 | Val Acc: 0.771720 loss: 0.895012\n",
            "[150/200] 117.99 sec(s) Train Acc: 0.919555 Loss: 0.245927 | Val Acc: 0.777551 loss: 0.905336\n",
            "[151/200] 117.95 sec(s) Train Acc: 0.921143 Loss: 0.246838 | Val Acc: 0.782216 loss: 0.869207\n",
            "[152/200] 117.61 sec(s) Train Acc: 0.921988 Loss: 0.240034 | Val Acc: 0.778426 loss: 0.876924\n",
            "[153/200] 117.91 sec(s) Train Acc: 0.922427 Loss: 0.244871 | Val Acc: 0.783090 loss: 0.890780\n",
            "[154/200] 117.88 sec(s) Train Acc: 0.922900 Loss: 0.238538 | Val Acc: 0.788630 loss: 0.860454\n",
            "[155/200] 117.93 sec(s) Train Acc: 0.921751 Loss: 0.238867 | Val Acc: 0.781633 loss: 0.881575\n",
            "[156/200] 117.82 sec(s) Train Acc: 0.920265 Loss: 0.245146 | Val Acc: 0.776968 loss: 0.883245\n",
            "[157/200] 117.78 sec(s) Train Acc: 0.923779 Loss: 0.234867 | Val Acc: 0.783382 loss: 0.891751\n",
            "[158/200] 117.67 sec(s) Train Acc: 0.922089 Loss: 0.237669 | Val Acc: 0.780175 loss: 0.877511\n",
            "[159/200] 117.71 sec(s) Train Acc: 0.921515 Loss: 0.239394 | Val Acc: 0.771429 loss: 0.884481\n",
            "[160/200] 117.64 sec(s) Train Acc: 0.924218 Loss: 0.232535 | Val Acc: 0.773178 loss: 0.884302\n",
            "[161/200] 117.44 sec(s) Train Acc: 0.927022 Loss: 0.226490 | Val Acc: 0.776385 loss: 0.916940\n",
            "[162/200] 117.75 sec(s) Train Acc: 0.926245 Loss: 0.228791 | Val Acc: 0.782799 loss: 0.878159\n",
            "[163/200] 117.70 sec(s) Train Acc: 0.924589 Loss: 0.234436 | Val Acc: 0.779883 loss: 0.882765\n",
            "[164/200] 117.72 sec(s) Train Acc: 0.922258 Loss: 0.238539 | Val Acc: 0.778426 loss: 0.865043\n",
            "[165/200] 117.61 sec(s) Train Acc: 0.923069 Loss: 0.236325 | Val Acc: 0.772886 loss: 0.919683\n",
            "[166/200] 117.70 sec(s) Train Acc: 0.927090 Loss: 0.223859 | Val Acc: 0.783382 loss: 0.899846\n",
            "[167/200] 117.54 sec(s) Train Acc: 0.922393 Loss: 0.237917 | Val Acc: 0.778134 loss: 0.902395\n",
            "[168/200] 117.77 sec(s) Train Acc: 0.926988 Loss: 0.228816 | Val Acc: 0.781924 loss: 0.851668\n",
            "[169/200] 117.82 sec(s) Train Acc: 0.922495 Loss: 0.235372 | Val Acc: 0.782799 loss: 0.887981\n",
            "[170/200] 118.44 sec(s) Train Acc: 0.926042 Loss: 0.226206 | Val Acc: 0.781633 loss: 0.906927\n",
            "[171/200] 117.85 sec(s) Train Acc: 0.927292 Loss: 0.228425 | Val Acc: 0.770262 loss: 0.899419\n",
            "[172/200] 117.95 sec(s) Train Acc: 0.924961 Loss: 0.234531 | Val Acc: 0.784840 loss: 0.865512\n",
            "[173/200] 117.79 sec(s) Train Acc: 0.925637 Loss: 0.229122 | Val Acc: 0.783090 loss: 0.890800\n",
            "[174/200] 117.58 sec(s) Train Acc: 0.925975 Loss: 0.230039 | Val Acc: 0.779009 loss: 0.876343\n",
            "[175/200] 117.90 sec(s) Train Acc: 0.926245 Loss: 0.224936 | Val Acc: 0.774636 loss: 0.948154\n",
            "[176/200] 117.70 sec(s) Train Acc: 0.924488 Loss: 0.233946 | Val Acc: 0.774636 loss: 0.915544\n",
            "[177/200] 117.40 sec(s) Train Acc: 0.927968 Loss: 0.222576 | Val Acc: 0.781341 loss: 0.892353\n",
            "[178/200] 117.57 sec(s) Train Acc: 0.923846 Loss: 0.234630 | Val Acc: 0.782799 loss: 0.900679\n",
            "[179/200] 117.42 sec(s) Train Acc: 0.928137 Loss: 0.221564 | Val Acc: 0.779883 loss: 0.925973\n",
            "[180/200] 117.71 sec(s) Train Acc: 0.925536 Loss: 0.226510 | Val Acc: 0.774927 loss: 0.907208\n",
            "[181/200] 117.48 sec(s) Train Acc: 0.927799 Loss: 0.222136 | Val Acc: 0.784548 loss: 0.859819\n",
            "[182/200] 117.43 sec(s) Train Acc: 0.926583 Loss: 0.226017 | Val Acc: 0.788338 loss: 0.871691\n",
            "[183/200] 117.78 sec(s) Train Acc: 0.928103 Loss: 0.219750 | Val Acc: 0.788047 loss: 0.877370\n",
            "[184/200] 117.75 sec(s) Train Acc: 0.927698 Loss: 0.217960 | Val Acc: 0.783382 loss: 0.896605\n",
            "[185/200] 117.85 sec(s) Train Acc: 0.927259 Loss: 0.223339 | Val Acc: 0.785423 loss: 0.879628\n",
            "[186/200] 117.73 sec(s) Train Acc: 0.929286 Loss: 0.219028 | Val Acc: 0.789213 loss: 0.878639\n",
            "[187/200] 117.70 sec(s) Train Acc: 0.929117 Loss: 0.222562 | Val Acc: 0.781633 loss: 0.912745\n",
            "[188/200] 117.67 sec(s) Train Acc: 0.928948 Loss: 0.220917 | Val Acc: 0.782216 loss: 0.897190\n",
            "[189/200] 117.51 sec(s) Train Acc: 0.928948 Loss: 0.222196 | Val Acc: 0.783382 loss: 0.885661\n",
            "[190/200] 118.06 sec(s) Train Acc: 0.927799 Loss: 0.219294 | Val Acc: 0.782799 loss: 0.889115\n",
            "[191/200] 117.60 sec(s) Train Acc: 0.926346 Loss: 0.226919 | Val Acc: 0.783673 loss: 0.836869\n",
            "[192/200] 117.71 sec(s) Train Acc: 0.928880 Loss: 0.216429 | Val Acc: 0.778717 loss: 0.910453\n",
            "[193/200] 117.81 sec(s) Train Acc: 0.930502 Loss: 0.212022 | Val Acc: 0.774636 loss: 0.919087\n",
            "[194/200] 117.61 sec(s) Train Acc: 0.929691 Loss: 0.218577 | Val Acc: 0.779300 loss: 0.946547\n",
            "[195/200] 117.55 sec(s) Train Acc: 0.930029 Loss: 0.214796 | Val Acc: 0.783382 loss: 0.888700\n",
            "[196/200] 117.86 sec(s) Train Acc: 0.930198 Loss: 0.215760 | Val Acc: 0.779883 loss: 0.900263\n",
            "[197/200] 117.65 sec(s) Train Acc: 0.929556 Loss: 0.219320 | Val Acc: 0.781050 loss: 0.874564\n",
            "[198/200] 117.67 sec(s) Train Acc: 0.930772 Loss: 0.214118 | Val Acc: 0.783965 loss: 0.889090\n",
            "[199/200] 118.06 sec(s) Train Acc: 0.927191 Loss: 0.220584 | Val Acc: 0.777259 loss: 0.906857\n",
            "[200/200] 117.83 sec(s) Train Acc: 0.931549 Loss: 0.210790 | Val Acc: 0.778426 loss: 0.916338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiMQq6dRHxkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai7Qs8wxIaqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}