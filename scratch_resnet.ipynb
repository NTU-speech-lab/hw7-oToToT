{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "scratch_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkYS9CnIGmHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-atKwH4GmHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "IN_IPYTHON = True\n",
        "try:\n",
        "    __IPYTHON__\n",
        "except NameError:\n",
        "    IN_IPYTHON = False\n",
        "\n",
        "if IN_IPYTHON:\n",
        "    workspace_dir, output_fpath = 'food-11', 'predict.csv'\n",
        "else:\n",
        "    try:\n",
        "        workspace_dir = sys.argv[1]\n",
        "    except:\n",
        "        workspace_dir = 'food-11'\n",
        "\n",
        "    try:\n",
        "        output_fpath = sys.argv[2]\n",
        "    except:\n",
        "        output_fpath = \"predict.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MP7YANtGmHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "IMAGE_SIZE = 192\n",
        "def readfile(path, label):\n",
        "    # label 是一個 boolean variable，代表需不需要回傳 y 值\n",
        "    image_dir = sorted(os.listdir(path))\n",
        "    x = np.zeros((len(image_dir), IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.uint8)\n",
        "    y = np.zeros((len(image_dir)), dtype=np.uint8)\n",
        "    for i, file in enumerate(image_dir):\n",
        "        img = cv2.imread(os.path.join(path, file))\n",
        "        # resize to IMAGE_SIZE x ? or ? x IMAGE_SIZE\n",
        "        height = img.shape[0]\n",
        "        width = img.shape[1]\n",
        "        rate = IMAGE_SIZE / max(height, width)\n",
        "        height = int(height * rate)\n",
        "        width = int(width * rate)\n",
        "        img = cv2.resize(img, (width, height))\n",
        "        # pad black\n",
        "        # from https://blog.csdn.net/qq_20622615/article/details/80929746\n",
        "        W, H = IMAGE_SIZE, IMAGE_SIZE\n",
        "        top = (H - height) // 2\n",
        "        bottom = (H - height) // 2\n",
        "        if top + bottom + height < H:\n",
        "            bottom += 1\n",
        "        left = (W - width) // 2\n",
        "        right = (W - width) // 2\n",
        "        if left + right + width < W:\n",
        "            right += 1\n",
        "        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
        "        # to np array\n",
        "        x[i, :, :] = img\n",
        "        if label:\n",
        "            y[i] = int(file.split(\"_\")[0])\n",
        "    if label:\n",
        "      return x, y\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtXR-Wf1GmHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform_mean = np.array([ 69.58238342,  92.66689336, 115.24940137]) / 255\n",
        "transform_std = np.array([71.8342021 , 76.83536755, 83.40123168]) / 255\n",
        "\n",
        "train_transform1 = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomChoice([\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomPerspective()\n",
        "    ]),\n",
        "    transforms.RandomChoice([\n",
        "        transforms.RandomAffine(10), # 隨機線性轉換\n",
        "        transforms.RandomRotation(40)\n",
        "    ]),\n",
        "    transforms.ColorJitter(), # 隨機色溫等\n",
        "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization)\n",
        "    transforms.Normalize(\n",
        "        transform_mean,\n",
        "        transform_std\n",
        "    )\n",
        "])\n",
        "train_transform2 = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomOrder([\n",
        "        transforms.RandomChoice([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomPerspective()\n",
        "        ]),\n",
        "        transforms.RandomAffine(30), # 隨機線性轉換\n",
        "        transforms.RandomResizedCrop((IMAGE_SIZE, IMAGE_SIZE), scale=(0.5, 1.0)), # 隨機子圖\n",
        "    ]),\n",
        "    transforms.RandomChoice([\n",
        "        transforms.ColorJitter(), # 隨機色溫等\n",
        "        transforms.RandomGrayscale(),\n",
        "    ]),\n",
        "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization)\n",
        "    transforms.RandomErasing(0.2),\n",
        "    transforms.Normalize(\n",
        "        transform_mean,\n",
        "        transform_std\n",
        "    )\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),                                    \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        transform_mean,\n",
        "        transform_std\n",
        "    )\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPkHsfTHGmHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import torch\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, folderName, transform=None):\n",
        "        self.transform = transform\n",
        "        self.img_paths = []\n",
        "\n",
        "        for img_path in sorted(glob(folderName + '/*.jpg')):\n",
        "            self.img_paths.append(img_path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "        try:\n",
        "            # Get classIdx by parsing image path\n",
        "            class_idx = int(re.findall(re.compile(r'\\d+'), self.img_paths[idx])[1])\n",
        "        except:\n",
        "            # if inference mode (there's no answer), class_idx default 0\n",
        "            class_idx = 0\n",
        "\n",
        "        image = Image.open(self.img_paths[idx])\n",
        "        # Get File Descriptor\n",
        "        image_fp = image.fp\n",
        "        image.load()\n",
        "        # Close File Descriptor (or it'll reach OPEN_MAX)\n",
        "        image_fp.close()\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, class_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "\n",
        "trainTransform = transforms.Compose([\n",
        "    transforms.RandomCrop(256, pad_if_needed=True, padding_mode='symmetric'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "testTransform = transforms.Compose([\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def get_dataloader(mode='training', batch_size=32):\n",
        "\n",
        "    assert mode in ['training', 'testing', 'validation']\n",
        "\n",
        "    dataset = MyDataset(\n",
        "        f'./food-11/{mode}',\n",
        "        transform=trainTransform if mode == 'training' else testTransform)\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(mode == 'training'))\n",
        "\n",
        "    return dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFjUSeuyGmHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = get_dataloader('training', batch_size=32)\n",
        "val_loader = get_dataloader('validation', batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrRyhJaiGmHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "f9453869-1548-473f-e8b1-c173c2e6ea69"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "!gdown --id '1VEoKts_clMcJYKnuUdxcNX1BtPcPTmsc' --output 'teacher_resnet18.bin'\n",
        "teacher_net = models.resnet18(pretrained=False, num_classes=11).cuda()\n",
        "teacher_net.load_state_dict(torch.load('teacher_resnet18.bin'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VEoKts_clMcJYKnuUdxcNX1BtPcPTmsc\n",
            "To: /content/teacher_resnet18.bin\n",
            "44.8MB [00:00, 108MB/s] \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFePu3O2GmHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class swish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(swish, self).__init__()\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = x * F.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class StudentNet(nn.Module):\n",
        "    '''\n",
        "      在這個Net裡面，我們會使用Depthwise & Pointwise Convolution Layer來疊model。\n",
        "      你會發現，將原本的Convolution Layer換成Dw & Pw後，Accuracy通常不會降很多。\n",
        "\n",
        "      另外，取名為StudentNet是因為這個Model等會要做Knowledge Distillation。\n",
        "    '''\n",
        "\n",
        "    def __init__(self, base=16, width_mult=1):\n",
        "        '''\n",
        "          Args:\n",
        "            base: 這個model一開始的ch數量，每過一層都會*2，直到base*16為止。\n",
        "            width_mult: 為了之後的Network Pruning使用，在base*8 chs的Layer上會 * width_mult代表剪枝後的ch數量。        \n",
        "        '''\n",
        "        super(StudentNet, self).__init__()\n",
        "        multiplier = [2, 4, 8, 8, 8, 16, 16, 16, 16]\n",
        "\n",
        "        # bandwidth: 每一層Layer所使用的ch數量\n",
        "        bandwidth = [int(base * m) for m in multiplier]\n",
        "\n",
        "        # 我們只Pruning第三層以後的Layer\n",
        "        for i in range(4, 8):\n",
        "            bandwidth[i] = int(bandwidth[i] * width_mult)\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            # 第一層我們通常不會拆解Convolution Layer。\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(3, bandwidth[0], 3, 1, 1),\n",
        "                nn.BatchNorm2d(bandwidth[0]),\n",
        "                nn.ReLU6(),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "            # 接下來每一個Sequential Block都一樣，所以我們只講一個Block\n",
        "            nn.Sequential(\n",
        "                # Depthwise Convolution\n",
        "                nn.Conv2d(bandwidth[0], bandwidth[0], 3, 1, 1, groups=bandwidth[0]),\n",
        "                # Batch Normalization\n",
        "                nn.BatchNorm2d(bandwidth[0]),\n",
        "                # ReLU6 是限制Neuron最小只會到0，最大只會到6。 MobileNet系列都是使用ReLU6。\n",
        "                # 使用ReLU6的原因是因為如果數字太大，會不好壓到float16 / or further qunatization，因此才給個限制。\n",
        "                nn.ReLU6(),\n",
        "                # Pointwise Convolution\n",
        "                nn.Conv2d(bandwidth[0], bandwidth[1], 1),\n",
        "                # 過完Pointwise Convolution不需要再做ReLU，經驗上Pointwise + ReLU效果都會變差。\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "                # 每過完一個Block就Down Sampling\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[1], bandwidth[1], 3, 1, 1, groups=bandwidth[1]),\n",
        "                nn.BatchNorm2d(bandwidth[1]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[1], bandwidth[2], 1),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[2], bandwidth[2], 3, 1, 1, groups=bandwidth[2]),\n",
        "                nn.BatchNorm2d(bandwidth[2]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[2], bandwidth[3], 1),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "            \n",
        "            # 到這邊為止因為圖片已經被Down Sample很多次了，所以就不做MaxPool\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[3], bandwidth[3], 3, 1, 1, groups=bandwidth[3]),\n",
        "                nn.BatchNorm2d(bandwidth[3]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[3], bandwidth[4], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[4], bandwidth[4], 3, 1, 1, groups=bandwidth[4]),\n",
        "                nn.BatchNorm2d(bandwidth[4]),\n",
        "                swish(),\n",
        "                nn.Conv2d(bandwidth[4], bandwidth[5], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[5], bandwidth[5], 3, 1, 1, groups=bandwidth[5]),\n",
        "                nn.BatchNorm2d(bandwidth[5]),\n",
        "                swish(),\n",
        "                nn.Conv2d(bandwidth[5], bandwidth[6], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[6], bandwidth[6], 3, 1, 1, groups=bandwidth[6]),\n",
        "                nn.BatchNorm2d(bandwidth[6]),\n",
        "                swish(),\n",
        "                nn.Conv2d(bandwidth[6], bandwidth[7], 1),\n",
        "            ),\n",
        "            \n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[7], bandwidth[7], 3, 1, 1, groups=bandwidth[7]),\n",
        "                nn.BatchNorm2d(bandwidth[7]),\n",
        "                swish(),\n",
        "                nn.Conv2d(bandwidth[7], bandwidth[8], 1),\n",
        "            ),\n",
        "\n",
        "            # 這邊我們採用Global Average Pooling。\n",
        "            # 如果輸入圖片大小不一樣的話，就會因為Global Average Pooling壓成一樣的形狀，這樣子接下來做FC就不會對不起來。\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # 這邊我們直接Project到11維輸出答案。\n",
        "            nn.Linear(bandwidth[8], 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU6(),\n",
        "            \n",
        "            nn.Dropout(0.4),\n",
        "            \n",
        "            nn.Linear(128, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            swish(),\n",
        "                        \n",
        "            nn.Linear(128, 11)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return self.fc(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vVeipg5GmHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn_kd(outputs, labels, teacher_outputs, T=20, alpha=0.5):\n",
        "    # 一般的Cross Entropy\n",
        "    hard_loss = F.cross_entropy(outputs, labels) * (1. - alpha)\n",
        "    # 讓logits的log_softmax對目標機率(teacher的logits/T後softmax)做KL Divergence。\n",
        "    soft_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs/T, dim=1),\n",
        "                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T)\n",
        "    return hard_loss + soft_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf1O2B20GmHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from torchvision.models import mobilenet_v2\n",
        "# student_net = mobilenet_v2(\n",
        "#     num_classes=11,\n",
        "#     width_mult=0.6,\n",
        "#     round_nearest=4,\n",
        "#     inverted_residual_setting = [\n",
        "#         # t, c, n, s\n",
        "#         [1, 16, 1, 1],\n",
        "#         [6, 24, 2, 2],\n",
        "# #         [6, 32, 3, 2],\n",
        "#         [6, 64, 4, 2],\n",
        "#         [6, 96, 3, 1],\n",
        "# #         [6, 160, 3, 2],\n",
        "#         [6, 320, 1, 1],\n",
        "#     ]\n",
        "# ).cuda()\n",
        "\n",
        "student_net_base = 9.5\n",
        "student_net = StudentNet(student_net_base).cuda()\n",
        "# student_net.load_state_dict(torch.load('student_model.bin'))\n",
        "\n",
        "optimizer = torch.optim.Adam(student_net.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJzVNqWdGmHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_epoch(dataloader, update=True, alpha=0.5):\n",
        "    total_num, total_hit, total_loss = 0, 0, 0\n",
        "    for now_step, batch_data in enumerate(dataloader):\n",
        "        # 清空 optimizer\n",
        "        optimizer.zero_grad()\n",
        "        # 處理 input\n",
        "        inputs, hard_labels = batch_data\n",
        "        inputs = inputs.cuda()\n",
        "        hard_labels = torch.LongTensor(hard_labels).cuda()\n",
        "        # 因為Teacher沒有要backprop，所以我們使用torch.no_grad\n",
        "        # 告訴torch不要暫存中間值(去做backprop)以浪費記憶體空間。\n",
        "        with torch.no_grad():\n",
        "            soft_labels = teacher_net(inputs)\n",
        "\n",
        "        if update:\n",
        "            logits = student_net(inputs)\n",
        "            # 使用我們之前所寫的融合soft label&hard label的loss。\n",
        "            # T=20是原始論文的參數設定。\n",
        "            loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n",
        "            loss.backward()\n",
        "            optimizer.step()    \n",
        "        else:\n",
        "            # 只是算validation acc的話，就開no_grad節省空間。\n",
        "            with torch.no_grad():\n",
        "                logits = student_net(inputs)\n",
        "                loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n",
        "            \n",
        "        total_hit += torch.sum(torch.argmax(logits, dim=1) == hard_labels).item()\n",
        "        total_num += len(inputs)\n",
        "\n",
        "        total_loss += loss.item() * len(inputs)\n",
        "    return total_loss / total_num, total_hit / total_num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "AqZZEoAKGmH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f7b5e71-d177-40f3-8a27-fd1e279b75ba"
      },
      "source": [
        "import time\n",
        "\n",
        "num_epoch = 200\n",
        "\n",
        "# TeacherNet永遠都是Eval mode.\n",
        "teacher_net.eval()\n",
        "now_best_acc = 0\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time = time.time()\n",
        "    \n",
        "    student_net.train()\n",
        "    train_loss, train_acc = run_epoch(train_loader, update=True)\n",
        "\n",
        "    student_net.eval()\n",
        "    valid_loss, valid_acc = run_epoch(val_loader, update=False)\n",
        "\n",
        "    # 存下最好的model。\n",
        "    if valid_acc > now_best_acc:\n",
        "        now_best_acc = valid_acc\n",
        "        torch.save(student_net.state_dict(), 'student_model.bin')\n",
        "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \n",
        "            (epoch + 1, num_epoch, time.time()-epoch_start_time, train_acc,\n",
        "            train_loss, valid_acc, valid_loss))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[001/200] 107.90 sec(s) Train Acc: 0.295865 Loss: 9.149074 | Val Acc: 0.375802 loss: 8.638342\n",
            "[002/200] 107.91 sec(s) Train Acc: 0.361849 Loss: 8.163229 | Val Acc: 0.418076 loss: 8.049739\n",
            "[003/200] 107.66 sec(s) Train Acc: 0.409690 Loss: 7.580004 | Val Acc: 0.462682 loss: 7.130517\n",
            "[004/200] 107.80 sec(s) Train Acc: 0.450334 Loss: 7.074879 | Val Acc: 0.484257 loss: 6.882523\n",
            "[005/200] 107.70 sec(s) Train Acc: 0.466349 Loss: 6.895110 | Val Acc: 0.500000 loss: 6.642942\n",
            "[006/200] 107.57 sec(s) Train Acc: 0.481147 Loss: 6.611683 | Val Acc: 0.544898 loss: 6.144122\n",
            "[007/200] 107.77 sec(s) Train Acc: 0.503446 Loss: 6.419652 | Val Acc: 0.525364 loss: 5.994072\n",
            "[008/200] 107.46 sec(s) Train Acc: 0.516825 Loss: 6.174447 | Val Acc: 0.538776 loss: 6.220315\n",
            "[009/200] 107.99 sec(s) Train Acc: 0.537503 Loss: 5.995267 | Val Acc: 0.576385 loss: 5.402094\n",
            "[010/200] 108.59 sec(s) Train Acc: 0.534563 Loss: 5.903366 | Val Acc: 0.574052 loss: 5.468960\n",
            "[011/200] 108.46 sec(s) Train Acc: 0.554328 Loss: 5.743273 | Val Acc: 0.607289 loss: 5.150767\n",
            "[012/200] 107.75 sec(s) Train Acc: 0.560714 Loss: 5.618165 | Val Acc: 0.589504 loss: 5.044429\n",
            "[013/200] 107.57 sec(s) Train Acc: 0.571964 Loss: 5.492392 | Val Acc: 0.595627 loss: 4.978315\n",
            "[014/200] 107.70 sec(s) Train Acc: 0.582303 Loss: 5.350008 | Val Acc: 0.581633 loss: 5.156405\n",
            "[015/200] 108.33 sec(s) Train Acc: 0.584837 Loss: 5.318630 | Val Acc: 0.623615 loss: 4.861193\n",
            "[016/200] 108.43 sec(s) Train Acc: 0.594770 Loss: 5.198411 | Val Acc: 0.637318 loss: 4.391495\n",
            "[017/200] 107.63 sec(s) Train Acc: 0.600953 Loss: 5.043250 | Val Acc: 0.614286 loss: 4.988162\n",
            "[018/200] 107.51 sec(s) Train Acc: 0.612812 Loss: 4.916409 | Val Acc: 0.648688 loss: 4.301465\n",
            "[019/200] 107.44 sec(s) Train Acc: 0.616765 Loss: 4.817263 | Val Acc: 0.657434 loss: 4.256572\n",
            "[020/200] 107.46 sec(s) Train Acc: 0.614737 Loss: 4.872111 | Val Acc: 0.649271 loss: 4.340666\n",
            "[021/200] 107.69 sec(s) Train Acc: 0.620819 Loss: 4.742984 | Val Acc: 0.659475 loss: 4.143586\n",
            "[022/200] 107.57 sec(s) Train Acc: 0.627306 Loss: 4.648934 | Val Acc: 0.638484 loss: 4.513652\n",
            "[023/200] 108.07 sec(s) Train Acc: 0.628725 Loss: 4.637078 | Val Acc: 0.668805 loss: 4.035373\n",
            "[024/200] 108.53 sec(s) Train Acc: 0.631766 Loss: 4.620652 | Val Acc: 0.662974 loss: 4.097266\n",
            "[025/200] 108.42 sec(s) Train Acc: 0.636124 Loss: 4.517892 | Val Acc: 0.674927 loss: 3.866572\n",
            "[026/200] 108.10 sec(s) Train Acc: 0.646361 Loss: 4.450461 | Val Acc: 0.675219 loss: 3.860739\n",
            "[027/200] 108.19 sec(s) Train Acc: 0.657207 Loss: 4.395199 | Val Acc: 0.681633 loss: 3.783523\n",
            "[028/200] 107.93 sec(s) Train Acc: 0.655382 Loss: 4.351703 | Val Acc: 0.684840 loss: 3.775760\n",
            "[029/200] 107.32 sec(s) Train Acc: 0.649909 Loss: 4.326173 | Val Acc: 0.692420 loss: 3.725567\n",
            "[030/200] 107.41 sec(s) Train Acc: 0.658322 Loss: 4.277627 | Val Acc: 0.697668 loss: 3.719550\n",
            "[031/200] 107.50 sec(s) Train Acc: 0.672714 Loss: 4.161549 | Val Acc: 0.700875 loss: 3.649266\n",
            "[032/200] 107.45 sec(s) Train Acc: 0.670484 Loss: 4.141585 | Val Acc: 0.684548 loss: 3.576909\n",
            "[033/200] 107.40 sec(s) Train Acc: 0.665417 Loss: 4.149756 | Val Acc: 0.675510 loss: 4.064455\n",
            "[034/200] 107.21 sec(s) Train Acc: 0.677275 Loss: 4.061711 | Val Acc: 0.692420 loss: 3.626482\n",
            "[035/200] 108.38 sec(s) Train Acc: 0.685992 Loss: 4.000305 | Val Acc: 0.689504 loss: 3.762153\n",
            "[036/200] 107.54 sec(s) Train Acc: 0.681837 Loss: 4.056023 | Val Acc: 0.691837 loss: 3.640649\n",
            "[037/200] 107.31 sec(s) Train Acc: 0.686296 Loss: 3.995198 | Val Acc: 0.708163 loss: 3.370133\n",
            "[038/200] 107.54 sec(s) Train Acc: 0.684979 Loss: 3.931298 | Val Acc: 0.714286 loss: 3.472555\n",
            "[039/200] 107.62 sec(s) Train Acc: 0.684371 Loss: 3.907609 | Val Acc: 0.715452 loss: 3.534254\n",
            "[040/200] 107.34 sec(s) Train Acc: 0.693898 Loss: 3.865186 | Val Acc: 0.705248 loss: 3.488038\n",
            "[041/200] 107.60 sec(s) Train Acc: 0.686600 Loss: 3.837769 | Val Acc: 0.730029 loss: 3.167223\n",
            "[042/200] 107.45 sec(s) Train Acc: 0.701196 Loss: 3.765819 | Val Acc: 0.699125 loss: 3.457701\n",
            "[043/200] 107.23 sec(s) Train Acc: 0.695419 Loss: 3.776502 | Val Acc: 0.692420 loss: 3.628193\n",
            "[044/200] 107.33 sec(s) Train Acc: 0.697953 Loss: 3.770691 | Val Acc: 0.709913 loss: 3.342931\n",
            "[045/200] 107.39 sec(s) Train Acc: 0.709203 Loss: 3.665028 | Val Acc: 0.727114 loss: 3.237734\n",
            "[046/200] 107.22 sec(s) Train Acc: 0.709406 Loss: 3.707504 | Val Acc: 0.711370 loss: 3.272059\n",
            "[047/200] 107.49 sec(s) Train Acc: 0.713967 Loss: 3.629946 | Val Acc: 0.733819 loss: 3.079761\n",
            "[048/200] 107.49 sec(s) Train Acc: 0.721366 Loss: 3.621486 | Val Acc: 0.722157 loss: 3.184560\n",
            "[049/200] 107.42 sec(s) Train Acc: 0.710521 Loss: 3.577416 | Val Acc: 0.714577 loss: 3.272163\n",
            "[050/200] 107.44 sec(s) Train Acc: 0.716298 Loss: 3.587559 | Val Acc: 0.723032 loss: 3.216184\n",
            "[051/200] 107.96 sec(s) Train Acc: 0.721366 Loss: 3.545340 | Val Acc: 0.714577 loss: 3.391448\n",
            "[052/200] 107.82 sec(s) Train Acc: 0.719745 Loss: 3.548618 | Val Acc: 0.718659 loss: 3.224569\n",
            "[053/200] 108.19 sec(s) Train Acc: 0.719136 Loss: 3.528421 | Val Acc: 0.742566 loss: 3.049878\n",
            "[054/200] 108.60 sec(s) Train Acc: 0.723191 Loss: 3.519813 | Val Acc: 0.736152 loss: 3.149597\n",
            "[055/200] 108.94 sec(s) Train Acc: 0.719238 Loss: 3.508974 | Val Acc: 0.742274 loss: 2.892433\n",
            "[056/200] 108.70 sec(s) Train Acc: 0.727144 Loss: 3.438952 | Val Acc: 0.737609 loss: 2.985796\n",
            "[057/200] 109.40 sec(s) Train Acc: 0.721873 Loss: 3.447228 | Val Acc: 0.736443 loss: 3.013059\n",
            "[058/200] 108.62 sec(s) Train Acc: 0.729576 Loss: 3.383617 | Val Acc: 0.738776 loss: 2.965077\n",
            "[059/200] 108.51 sec(s) Train Acc: 0.733023 Loss: 3.407377 | Val Acc: 0.720117 loss: 3.046806\n",
            "[060/200] 108.17 sec(s) Train Acc: 0.731299 Loss: 3.380840 | Val Acc: 0.741399 loss: 2.988663\n",
            "[061/200] 107.96 sec(s) Train Acc: 0.732313 Loss: 3.402248 | Val Acc: 0.740233 loss: 2.922993\n",
            "[062/200] 107.62 sec(s) Train Acc: 0.732110 Loss: 3.370482 | Val Acc: 0.753061 loss: 2.902780\n",
            "[063/200] 107.46 sec(s) Train Acc: 0.737685 Loss: 3.342215 | Val Acc: 0.749271 loss: 2.849082\n",
            "[064/200] 107.46 sec(s) Train Acc: 0.734948 Loss: 3.328821 | Val Acc: 0.733236 loss: 3.166206\n",
            "[065/200] 107.67 sec(s) Train Acc: 0.739003 Loss: 3.296782 | Val Acc: 0.739942 loss: 2.970505\n",
            "[066/200] 107.43 sec(s) Train Acc: 0.736874 Loss: 3.311716 | Val Acc: 0.741108 loss: 2.843336\n",
            "[067/200] 107.46 sec(s) Train Acc: 0.739712 Loss: 3.245010 | Val Acc: 0.746647 loss: 2.884530\n",
            "[068/200] 107.57 sec(s) Train Acc: 0.741638 Loss: 3.256028 | Val Acc: 0.735277 loss: 2.952464\n",
            "[069/200] 107.64 sec(s) Train Acc: 0.741537 Loss: 3.282829 | Val Acc: 0.730029 loss: 2.968136\n",
            "[070/200] 107.40 sec(s) Train Acc: 0.747821 Loss: 3.205749 | Val Acc: 0.745481 loss: 2.885992\n",
            "[071/200] 107.74 sec(s) Train Acc: 0.748429 Loss: 3.220086 | Val Acc: 0.749563 loss: 2.842740\n",
            "[072/200] 107.79 sec(s) Train Acc: 0.746503 Loss: 3.160593 | Val Acc: 0.759767 loss: 2.777218\n",
            "[073/200] 107.90 sec(s) Train Acc: 0.752179 Loss: 3.200993 | Val Acc: 0.723907 loss: 3.226181\n",
            "[074/200] 107.93 sec(s) Train Acc: 0.750152 Loss: 3.153024 | Val Acc: 0.754227 loss: 2.745357\n",
            "[075/200] 107.98 sec(s) Train Acc: 0.753700 Loss: 3.154500 | Val Acc: 0.756560 loss: 2.748043\n",
            "[076/200] 107.74 sec(s) Train Acc: 0.753091 Loss: 3.118107 | Val Acc: 0.757434 loss: 2.726849\n",
            "[077/200] 107.63 sec(s) Train Acc: 0.751875 Loss: 3.150297 | Val Acc: 0.752478 loss: 2.757625\n",
            "[078/200] 107.83 sec(s) Train Acc: 0.751470 Loss: 3.144768 | Val Acc: 0.759475 loss: 2.723344\n",
            "[079/200] 107.61 sec(s) Train Acc: 0.751166 Loss: 3.104878 | Val Acc: 0.745190 loss: 2.832357\n",
            "[080/200] 107.97 sec(s) Train Acc: 0.762923 Loss: 3.063249 | Val Acc: 0.747230 loss: 2.740226\n",
            "[081/200] 107.67 sec(s) Train Acc: 0.755727 Loss: 3.077504 | Val Acc: 0.756851 loss: 2.709304\n",
            "[082/200] 107.80 sec(s) Train Acc: 0.756234 Loss: 3.084924 | Val Acc: 0.746064 loss: 2.752554\n",
            "[083/200] 107.89 sec(s) Train Acc: 0.763025 Loss: 3.070145 | Val Acc: 0.746939 loss: 2.870985\n",
            "[084/200] 107.80 sec(s) Train Acc: 0.760896 Loss: 3.027788 | Val Acc: 0.758309 loss: 2.672488\n",
            "[085/200] 107.94 sec(s) Train Acc: 0.759072 Loss: 3.073146 | Val Acc: 0.765015 loss: 2.709583\n",
            "[086/200] 107.92 sec(s) Train Acc: 0.758565 Loss: 3.045964 | Val Acc: 0.760933 loss: 2.705748\n",
            "[087/200] 107.80 sec(s) Train Acc: 0.769005 Loss: 3.030317 | Val Acc: 0.752770 loss: 2.692963\n",
            "[088/200] 107.96 sec(s) Train Acc: 0.766977 Loss: 2.989145 | Val Acc: 0.758601 loss: 2.558842\n",
            "[089/200] 107.80 sec(s) Train Acc: 0.768903 Loss: 2.994503 | Val Acc: 0.757726 loss: 2.640482\n",
            "[090/200] 108.05 sec(s) Train Acc: 0.764849 Loss: 3.002505 | Val Acc: 0.749854 loss: 2.762770\n",
            "[091/200] 108.36 sec(s) Train Acc: 0.772248 Loss: 2.936905 | Val Acc: 0.754519 loss: 2.730503\n",
            "[092/200] 108.07 sec(s) Train Acc: 0.768802 Loss: 2.962613 | Val Acc: 0.749563 loss: 2.753846\n",
            "[093/200] 108.24 sec(s) Train Acc: 0.762518 Loss: 2.958963 | Val Acc: 0.757726 loss: 2.680643\n",
            "[094/200] 108.37 sec(s) Train Acc: 0.774579 Loss: 2.919481 | Val Acc: 0.765889 loss: 2.547741\n",
            "[095/200] 108.11 sec(s) Train Acc: 0.767383 Loss: 2.952883 | Val Acc: 0.748688 loss: 2.759610\n",
            "[096/200] 107.89 sec(s) Train Acc: 0.771843 Loss: 2.928523 | Val Acc: 0.758601 loss: 2.648919\n",
            "[097/200] 108.16 sec(s) Train Acc: 0.773870 Loss: 2.898785 | Val Acc: 0.767347 loss: 2.577112\n",
            "[098/200] 107.90 sec(s) Train Acc: 0.778735 Loss: 2.875143 | Val Acc: 0.747522 loss: 2.655692\n",
            "[099/200] 107.88 sec(s) Train Acc: 0.774478 Loss: 2.903290 | Val Acc: 0.762391 loss: 2.647285\n",
            "[100/200] 107.94 sec(s) Train Acc: 0.779850 Loss: 2.892587 | Val Acc: 0.781050 loss: 2.528761\n",
            "[101/200] 107.69 sec(s) Train Acc: 0.774782 Loss: 2.896819 | Val Acc: 0.766764 loss: 2.470904\n",
            "[102/200] 107.59 sec(s) Train Acc: 0.774782 Loss: 2.877087 | Val Acc: 0.769096 loss: 2.570284\n",
            "[103/200] 107.17 sec(s) Train Acc: 0.775390 Loss: 2.872574 | Val Acc: 0.756268 loss: 2.654211\n",
            "[104/200] 107.14 sec(s) Train Acc: 0.775998 Loss: 2.863670 | Val Acc: 0.765306 loss: 2.581056\n",
            "[105/200] 107.20 sec(s) Train Acc: 0.777924 Loss: 2.852169 | Val Acc: 0.766181 loss: 2.556138\n",
            "[106/200] 107.87 sec(s) Train Acc: 0.778228 Loss: 2.862075 | Val Acc: 0.767638 loss: 2.543447\n",
            "[107/200] 107.53 sec(s) Train Acc: 0.787959 Loss: 2.844228 | Val Acc: 0.768513 loss: 2.481483\n",
            "[108/200] 107.86 sec(s) Train Acc: 0.780154 Loss: 2.840392 | Val Acc: 0.775510 loss: 2.526817\n",
            "[109/200] 107.73 sec(s) Train Acc: 0.778026 Loss: 2.835731 | Val Acc: 0.768513 loss: 2.599943\n",
            "[110/200] 107.37 sec(s) Train Acc: 0.785830 Loss: 2.814405 | Val Acc: 0.776968 loss: 2.592046\n",
            "[111/200] 106.88 sec(s) Train Acc: 0.779647 Loss: 2.840514 | Val Acc: 0.764431 loss: 2.489997\n",
            "[112/200] 106.46 sec(s) Train Acc: 0.781269 Loss: 2.821044 | Val Acc: 0.757434 loss: 2.575832\n",
            "[113/200] 106.12 sec(s) Train Acc: 0.785425 Loss: 2.777922 | Val Acc: 0.771429 loss: 2.541164\n",
            "[114/200] 106.17 sec(s) Train Acc: 0.777417 Loss: 2.811936 | Val Acc: 0.755685 loss: 2.648213\n",
            "[115/200] 106.38 sec(s) Train Acc: 0.781674 Loss: 2.811034 | Val Acc: 0.771429 loss: 2.602573\n",
            "[116/200] 106.18 sec(s) Train Acc: 0.789276 Loss: 2.780713 | Val Acc: 0.771137 loss: 2.597275\n",
            "[117/200] 106.27 sec(s) Train Acc: 0.789580 Loss: 2.738685 | Val Acc: 0.772303 loss: 2.526038\n",
            "[118/200] 106.29 sec(s) Train Acc: 0.789276 Loss: 2.738337 | Val Acc: 0.767055 loss: 2.564378\n",
            "[119/200] 105.96 sec(s) Train Acc: 0.790087 Loss: 2.764332 | Val Acc: 0.771720 loss: 2.497509\n",
            "[120/200] 106.27 sec(s) Train Acc: 0.792013 Loss: 2.741660 | Val Acc: 0.763557 loss: 2.585315\n",
            "[121/200] 106.38 sec(s) Train Acc: 0.793128 Loss: 2.763238 | Val Acc: 0.774052 loss: 2.468704\n",
            "[122/200] 105.71 sec(s) Train Acc: 0.794648 Loss: 2.714046 | Val Acc: 0.765015 loss: 2.583530\n",
            "[123/200] 106.58 sec(s) Train Acc: 0.788972 Loss: 2.740443 | Val Acc: 0.761808 loss: 2.459038\n",
            "[124/200] 107.53 sec(s) Train Acc: 0.795155 Loss: 2.709203 | Val Acc: 0.771720 loss: 2.495152\n",
            "[125/200] 107.50 sec(s) Train Acc: 0.790493 Loss: 2.743709 | Val Acc: 0.771720 loss: 2.619442\n",
            "[126/200] 107.47 sec(s) Train Acc: 0.791405 Loss: 2.701057 | Val Acc: 0.773761 loss: 2.473423\n",
            "[127/200] 107.56 sec(s) Train Acc: 0.799412 Loss: 2.686899 | Val Acc: 0.769388 loss: 2.561946\n",
            "[128/200] 107.65 sec(s) Train Acc: 0.792520 Loss: 2.744402 | Val Acc: 0.781341 loss: 2.463665\n",
            "[129/200] 107.67 sec(s) Train Acc: 0.795662 Loss: 2.678736 | Val Acc: 0.761224 loss: 2.510927\n",
            "[130/200] 107.62 sec(s) Train Acc: 0.800527 Loss: 2.657406 | Val Acc: 0.762099 loss: 2.540880\n",
            "[131/200] 107.47 sec(s) Train Acc: 0.799513 Loss: 2.672054 | Val Acc: 0.762682 loss: 2.460523\n",
            "[132/200] 107.77 sec(s) Train Acc: 0.799311 Loss: 2.625428 | Val Acc: 0.776968 loss: 2.479907\n",
            "[133/200] 107.68 sec(s) Train Acc: 0.793128 Loss: 2.666395 | Val Acc: 0.776968 loss: 2.425375\n",
            "[134/200] 107.40 sec(s) Train Acc: 0.793128 Loss: 2.679409 | Val Acc: 0.774344 loss: 2.399703\n",
            "[135/200] 107.51 sec(s) Train Acc: 0.801845 Loss: 2.630825 | Val Acc: 0.779009 loss: 2.461247\n",
            "[136/200] 107.53 sec(s) Train Acc: 0.803568 Loss: 2.644990 | Val Acc: 0.778426 loss: 2.401768\n",
            "[137/200] 107.64 sec(s) Train Acc: 0.801338 Loss: 2.630427 | Val Acc: 0.771137 loss: 2.464732\n",
            "[138/200] 107.51 sec(s) Train Acc: 0.804480 Loss: 2.618204 | Val Acc: 0.767930 loss: 2.436074\n",
            "[139/200] 107.31 sec(s) Train Acc: 0.797486 Loss: 2.624765 | Val Acc: 0.776385 loss: 2.406826\n",
            "[140/200] 107.73 sec(s) Train Acc: 0.799007 Loss: 2.659886 | Val Acc: 0.773469 loss: 2.441898\n",
            "[141/200] 107.43 sec(s) Train Acc: 0.800020 Loss: 2.640459 | Val Acc: 0.776093 loss: 2.420146\n",
            "[142/200] 107.61 sec(s) Train Acc: 0.796169 Loss: 2.667400 | Val Acc: 0.774636 loss: 2.452795\n",
            "[143/200] 107.77 sec(s) Train Acc: 0.803162 Loss: 2.644083 | Val Acc: 0.782216 loss: 2.319498\n",
            "[144/200] 107.42 sec(s) Train Acc: 0.804075 Loss: 2.590898 | Val Acc: 0.777551 loss: 2.455868\n",
            "[145/200] 107.60 sec(s) Train Acc: 0.797993 Loss: 2.587253 | Val Acc: 0.783090 loss: 2.409270\n",
            "[146/200] 107.53 sec(s) Train Acc: 0.804075 Loss: 2.610169 | Val Acc: 0.776968 loss: 2.389395\n",
            "[147/200] 107.21 sec(s) Train Acc: 0.812994 Loss: 2.557991 | Val Acc: 0.783673 loss: 2.449169\n",
            "[148/200] 106.77 sec(s) Train Acc: 0.803264 Loss: 2.560329 | Val Acc: 0.763557 loss: 2.569761\n",
            "[149/200] 107.45 sec(s) Train Acc: 0.806304 Loss: 2.609155 | Val Acc: 0.783673 loss: 2.410629\n",
            "[150/200] 107.24 sec(s) Train Acc: 0.803061 Loss: 2.606735 | Val Acc: 0.776968 loss: 2.363403\n",
            "[151/200] 106.97 sec(s) Train Acc: 0.799412 Loss: 2.581374 | Val Acc: 0.786006 loss: 2.337951\n",
            "[152/200] 106.98 sec(s) Train Acc: 0.801845 Loss: 2.557936 | Val Acc: 0.777259 loss: 2.450409\n",
            "[153/200] 106.69 sec(s) Train Acc: 0.803568 Loss: 2.589697 | Val Acc: 0.779592 loss: 2.427127\n",
            "[154/200] 106.87 sec(s) Train Acc: 0.810156 Loss: 2.591180 | Val Acc: 0.780466 loss: 2.326758\n",
            "[155/200] 106.92 sec(s) Train Acc: 0.810663 Loss: 2.535070 | Val Acc: 0.781633 loss: 2.401066\n",
            "[156/200] 106.57 sec(s) Train Acc: 0.811778 Loss: 2.522107 | Val Acc: 0.779300 loss: 2.365411\n",
            "[157/200] 107.77 sec(s) Train Acc: 0.806811 Loss: 2.565355 | Val Acc: 0.771137 loss: 2.502596\n",
            "[158/200] 108.23 sec(s) Train Acc: 0.803771 Loss: 2.552974 | Val Acc: 0.776093 loss: 2.370795\n",
            "[159/200] 107.47 sec(s) Train Acc: 0.812082 Loss: 2.549680 | Val Acc: 0.779883 loss: 2.378885\n",
            "[160/200] 108.20 sec(s) Train Acc: 0.812082 Loss: 2.528801 | Val Acc: 0.778426 loss: 2.391436\n",
            "[161/200] 107.59 sec(s) Train Acc: 0.811676 Loss: 2.513969 | Val Acc: 0.777259 loss: 2.402659\n",
            "[162/200] 106.95 sec(s) Train Acc: 0.815731 Loss: 2.526109 | Val Acc: 0.779300 loss: 2.396166\n",
            "[163/200] 107.22 sec(s) Train Acc: 0.814210 Loss: 2.522363 | Val Acc: 0.780175 loss: 2.529134\n",
            "[164/200] 107.09 sec(s) Train Acc: 0.820495 Loss: 2.513795 | Val Acc: 0.780175 loss: 2.336521\n",
            "[165/200] 106.97 sec(s) Train Acc: 0.808940 Loss: 2.508245 | Val Acc: 0.771720 loss: 2.472083\n",
            "[166/200] 106.94 sec(s) Train Acc: 0.810055 Loss: 2.538644 | Val Acc: 0.773761 loss: 2.434623\n",
            "[167/200] 107.22 sec(s) Train Acc: 0.805392 Loss: 2.553299 | Val Acc: 0.781341 loss: 2.376465\n",
            "[168/200] 107.50 sec(s) Train Acc: 0.808838 Loss: 2.560333 | Val Acc: 0.777843 loss: 2.457518\n",
            "[169/200] 107.86 sec(s) Train Acc: 0.817048 Loss: 2.459374 | Val Acc: 0.780175 loss: 2.296377\n",
            "[170/200] 107.42 sec(s) Train Acc: 0.807217 Loss: 2.530567 | Val Acc: 0.775219 loss: 2.355218\n",
            "[171/200] 107.64 sec(s) Train Acc: 0.812791 Loss: 2.477584 | Val Acc: 0.777551 loss: 2.406430\n",
            "[172/200] 107.86 sec(s) Train Acc: 0.811474 Loss: 2.494264 | Val Acc: 0.770262 loss: 2.484653\n",
            "[173/200] 107.30 sec(s) Train Acc: 0.814819 Loss: 2.510729 | Val Acc: 0.775219 loss: 2.484247\n",
            "[174/200] 107.38 sec(s) Train Acc: 0.815427 Loss: 2.495841 | Val Acc: 0.781341 loss: 2.332565\n",
            "[175/200] 107.65 sec(s) Train Acc: 0.817454 Loss: 2.483911 | Val Acc: 0.771720 loss: 2.400762\n",
            "[176/200] 107.45 sec(s) Train Acc: 0.817251 Loss: 2.459029 | Val Acc: 0.778426 loss: 2.448516\n",
            "[177/200] 107.42 sec(s) Train Acc: 0.821610 Loss: 2.468793 | Val Acc: 0.780175 loss: 2.373173\n",
            "[178/200] 107.71 sec(s) Train Acc: 0.815528 Loss: 2.461122 | Val Acc: 0.782507 loss: 2.295074\n",
            "[179/200] 107.37 sec(s) Train Acc: 0.820393 Loss: 2.433014 | Val Acc: 0.768222 loss: 2.378833\n",
            "[180/200] 107.69 sec(s) Train Acc: 0.823434 Loss: 2.458023 | Val Acc: 0.778426 loss: 2.336691\n",
            "[181/200] 107.93 sec(s) Train Acc: 0.819380 Loss: 2.455413 | Val Acc: 0.783382 loss: 2.285209\n",
            "[182/200] 107.59 sec(s) Train Acc: 0.818873 Loss: 2.466392 | Val Acc: 0.783090 loss: 2.353977\n",
            "[183/200] 107.54 sec(s) Train Acc: 0.812285 Loss: 2.469797 | Val Acc: 0.791254 loss: 2.312363\n",
            "[184/200] 107.61 sec(s) Train Acc: 0.817251 Loss: 2.465543 | Val Acc: 0.774052 loss: 2.370147\n",
            "[185/200] 107.54 sec(s) Train Acc: 0.820900 Loss: 2.418345 | Val Acc: 0.780758 loss: 2.380812\n",
            "[186/200] 107.74 sec(s) Train Acc: 0.819886 Loss: 2.455286 | Val Acc: 0.779009 loss: 2.301038\n",
            "[187/200] 108.06 sec(s) Train Acc: 0.825360 Loss: 2.466384 | Val Acc: 0.776968 loss: 2.404394\n",
            "[188/200] 107.44 sec(s) Train Acc: 0.821305 Loss: 2.445293 | Val Acc: 0.770554 loss: 2.397767\n",
            "[189/200] 107.68 sec(s) Train Acc: 0.817758 Loss: 2.455565 | Val Acc: 0.776093 loss: 2.276717\n",
            "[190/200] 108.08 sec(s) Train Acc: 0.826475 Loss: 2.409940 | Val Acc: 0.788921 loss: 2.290720\n",
            "[191/200] 108.37 sec(s) Train Acc: 0.821103 Loss: 2.449138 | Val Acc: 0.779300 loss: 2.269927\n",
            "[192/200] 108.51 sec(s) Train Acc: 0.824853 Loss: 2.409038 | Val Acc: 0.786297 loss: 2.302867\n",
            "[193/200] 108.15 sec(s) Train Acc: 0.827995 Loss: 2.397616 | Val Acc: 0.770554 loss: 2.441975\n",
            "[194/200] 108.23 sec(s) Train Acc: 0.823839 Loss: 2.399111 | Val Acc: 0.786297 loss: 2.315862\n",
            "[195/200] 108.12 sec(s) Train Acc: 0.823029 Loss: 2.420101 | Val Acc: 0.772595 loss: 2.458970\n",
            "[196/200] 107.85 sec(s) Train Acc: 0.826475 Loss: 2.402534 | Val Acc: 0.784548 loss: 2.319596\n",
            "[197/200] 108.28 sec(s) Train Acc: 0.826779 Loss: 2.370525 | Val Acc: 0.773178 loss: 2.381218\n",
            "[198/200] 108.48 sec(s) Train Acc: 0.823231 Loss: 2.430259 | Val Acc: 0.785714 loss: 2.258680\n",
            "[199/200] 107.72 sec(s) Train Acc: 0.823333 Loss: 2.407681 | Val Acc: 0.769679 loss: 2.430081\n",
            "[200/200] 107.63 sec(s) Train Acc: 0.825664 Loss: 2.441114 | Val Acc: 0.780466 loss: 2.350241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTuZkRwaGmH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epoch = 0\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time = time.time()\n",
        "    \n",
        "    student_net.train()\n",
        "    train_loss, train_acc = run_epoch(train_loader, update=True, alpha=0)\n",
        "    student_net.eval()\n",
        "    valid_loss, valid_acc = run_epoch(val_loader, update=False, alpha=0)\n",
        "\n",
        "    # 存下最好的model。\n",
        "    if valid_acc > now_best_acc:\n",
        "        now_best_acc = valid_acc\n",
        "        torch.save(student_net.state_dict(), 'student_model.bin')\n",
        "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \n",
        "            (epoch + 1, num_epoch, time.time()-epoch_start_time, train_acc,\n",
        "            train_loss, valid_acc, valid_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}